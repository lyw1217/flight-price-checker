#!/usr/bin/env python3
"""
í…”ë ˆê·¸ë¨ ë´‡ìœ¼ë¡œ 30ë¶„ë§ˆë‹¤ í•­ê³µê¶Œ ìµœì €ê°€ ì¡°íšŒ ë° ì•Œë¦¼ ê¸°ëŠ¥ ì œê³µ
í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í•„ìˆ˜):
- BOT_TOKEN         : Telegram ë´‡ í† í°
- SELENIUM_HUB_URL  : Selenium Hub ì£¼ì†Œ (ê¸°ë³¸: http://localhost:4444/wd/hub)
- ADMIN_IDS         : ê´€ë¦¬ì ID ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„)
- USER_AGENT        : (ì„ íƒ) Selenium í—¤ë“œë¦¬ìŠ¤ ë¸Œë¼ìš°ì €ìš© User-Agent
- MAX_MONITORS      : (ì„ íƒ) ì‚¬ìš©ìë‹¹ ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ (ê¸°ë³¸ 3)
- DATA_RETENTION_DAYS: (ì„ íƒ) ëª¨ë‹ˆí„°ë§ ë°ì´í„° ë³´ê´€ ê¸°ê°„ (ì¼, ê¸°ë³¸ 30)
- CONFIG_RETENTION_DAYS: (ì„ íƒ) ì‚¬ìš©ì ì„¤ì • íŒŒì¼ ë³´ê´€ ê¸°ê°„ (ì¼, ê¸°ë³¸ 7)
- MAX_WORKERS       : (ì„ íƒ) ìµœëŒ€ ë™ì‹œ ì‘ì—…ì ìˆ˜ (ê¸°ë³¸ 10)
"""
import os
import re
import json
import time as time_module
import logging
import asyncio
import fcntl
import contextlib
from pathlib import Path
from datetime import datetime, timedelta, time
from zoneinfo import ZoneInfo
from collections import defaultdict
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor
from functools import partial
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, Message
from telegram.ext import (
    ApplicationBuilder, CommandHandler,
    MessageHandler, ConversationHandler,
    ContextTypes, filters, JobQueue,
    CallbackQueryHandler
)
from telegram import ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import sys
import threading
from typing import Optional, Tuple, Dict, Any
from telegram.error import BadRequest, TimedOut, NetworkError

# ì•ˆì „í•œ ë©”ì‹œì§€ í¸ì§‘ í•¨ìˆ˜
async def safe_edit_message(
    message: Message, 
    text: str, 
    parse_mode: str = None,
    reply_markup=None,
    disable_web_page_preview: bool = True,
    max_retries: int = 3
) -> Optional[Message]:
    """
    ì•ˆì „í•œ ë©”ì‹œì§€ í¸ì§‘ í•¨ìˆ˜
    - í¸ì§‘ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ìƒˆ ë©”ì‹œì§€ ë°œì†¡
    - ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ì‹œ ì¬ì‹œë„
    """
    for attempt in range(max_retries):
        try:
            return await message.edit_text(
                text=text,
                parse_mode=parse_mode,
                reply_markup=reply_markup,
                disable_web_page_preview=disable_web_page_preview
            )
        except BadRequest as e:
            error_msg = str(e).lower()
            
            if "message can't be edited" in error_msg:
                logger.warning(f"ë©”ì‹œì§€ í¸ì§‘ ë¶ˆê°€, ìƒˆ ë©”ì‹œì§€ ë°œì†¡: {e}")
                try:
                    return await message.reply_text(
                        text=text,
                        parse_mode=parse_mode,
                        reply_markup=reply_markup,
                        disable_web_page_preview=disable_web_page_preview
                    )
                except Exception as reply_error:
                    logger.error(f"ìƒˆ ë©”ì‹œì§€ ë°œì†¡ë„ ì‹¤íŒ¨: {reply_error}")
                    return None
            
            elif "message is not modified" in error_msg:
                logger.debug("ë©”ì‹œì§€ ë‚´ìš©ì´ ë™ì¼í•˜ì—¬ í¸ì§‘í•˜ì§€ ì•ŠìŒ")
                return message
            
            elif attempt < max_retries - 1:
                logger.warning(f"ë©”ì‹œì§€ í¸ì§‘ ì¬ì‹œë„ {attempt + 1}/{max_retries}: {e}")
                await asyncio.sleep(1)
                continue
            else:
                logger.error(f"ë©”ì‹œì§€ í¸ì§‘ ìµœì¢… ì‹¤íŒ¨: {e}")
                return None
                
        except (TimedOut, NetworkError) as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„
                logger.warning(f"ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬, {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                await asyncio.sleep(wait_time)
                continue
            else:
                logger.error(f"ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ìµœì¢… ì‹¤íŒ¨: {e}")
                return None
        
        except Exception as e:
            logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
            return None
    
    return None

# ë©”ì‹œì§€ ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤
class MessageManager:
    def __init__(self):
        # ì‚¬ìš©ìë³„ ìƒíƒœ ë©”ì‹œì§€ ì¶”ì 
        self.status_messages: Dict[int, Message] = {}
        # ë©”ì‹œì§€ í¸ì§‘ ì ê¸ˆ (ë™ì‹œ í¸ì§‘ ë°©ì§€)
        self.edit_locks: Dict[str, asyncio.Lock] = {}
    
    def get_lock(self, message_key: str) -> asyncio.Lock:
        """ë©”ì‹œì§€ë³„ í¸ì§‘ ì ê¸ˆ ë°˜í™˜"""
        if message_key not in self.edit_locks:
            self.edit_locks[message_key] = asyncio.Lock()
        return self.edit_locks[message_key]
    
    async def update_status_message(
        self, 
        user_id: int, 
        text: str, 
        parse_mode: str = "Markdown",
        reply_markup=None
    ) -> Optional[Message]:
        """ì‚¬ìš©ìë³„ ìƒíƒœ ë©”ì‹œì§€ ì—…ë°ì´íŠ¸"""
        message_key = f"status_{user_id}"
        
        async with self.get_lock(message_key):
            current_message = self.status_messages.get(user_id)
            
            if current_message:
                # ê¸°ì¡´ ë©”ì‹œì§€ í¸ì§‘ ì‹œë„
                updated_message = await safe_edit_message(
                    current_message, 
                    text, 
                    parse_mode=parse_mode,
                    reply_markup=reply_markup
                )
                
                if updated_message:
                    self.status_messages[user_id] = updated_message
                    return updated_message
                else:
                    # í¸ì§‘ ì‹¤íŒ¨ ì‹œ ìƒˆ ë©”ì‹œì§€ë¡œ êµì²´
                    del self.status_messages[user_id]
            
            return None
    
    def set_status_message(self, user_id: int, message: Message):
        """ìƒíƒœ ë©”ì‹œì§€ ë“±ë¡"""
        self.status_messages[user_id] = message
    
    def clear_status_message(self, user_id: int):
        """ìƒíƒœ ë©”ì‹œì§€ ì œê±°"""
        if user_id in self.status_messages:
            del self.status_messages[user_id]

# ì „ì—­ ë©”ì‹œì§€ ë§¤ë‹ˆì €
message_manager = MessageManager()

# Selenium ì‘ì—… ê´€ë¦¬ë¥¼ ìœ„í•œ ì „ìš© ë§¤ë‹ˆì € í´ë˜ìŠ¤
class SeleniumManager:
    def __init__(self, max_workers: int = 3, grid_url: str = None, user_agent: str = None):
        """
        Selenium ì‘ì—…ì„ ìœ„í•œ ì „ìš© ë§¤ë‹ˆì €
        
        Args:
            max_workers: ë™ì‹œ ì‹¤í–‰í•  ìµœëŒ€ ë¸Œë¼ìš°ì € ìˆ˜
            grid_url: Selenium Grid URL
            user_agent: ë¸Œë¼ìš°ì € User-Agent
        """
        self.executor = ThreadPoolExecutor(max_workers=max_workers, thread_name_prefix="selenium")
        self.grid_url = grid_url
        self.user_agent = user_agent
        self.active_tasks = 0
        self.lock = threading.Lock()
    
    def setup_driver(self) -> webdriver.Remote:
        """ë¸Œë¼ìš°ì € ë“œë¼ì´ë²„ ì„¤ì •"""
        options = webdriver.ChromeOptions()
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--headless')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        if self.user_agent:
            options.add_argument(f'user-agent={self.user_agent}')
        
        if self.grid_url:
            # Selenium Grid ì‚¬ìš©
            driver = webdriver.Remote(
                command_executor=self.grid_url,
                options=options
            )
        else:
            # ë¡œì»¬ ChromeDriver ì‚¬ìš©
            driver = webdriver.Chrome(options=options)
        
        return driver
    
    def _fetch_single(self, url: str, depart: str, arrive: str, config: dict) -> Tuple[Any, str, Any, str, str]:
        """ë‹¨ì¼ ì¡°íšŒ ì‹¤í–‰ (ë™ê¸° í•¨ìˆ˜)"""
        with self.lock:
            self.active_tasks += 1
            task_id = self.active_tasks
        
        logger.info(f"Selenium ì‘ì—… ì‹œì‘ #{task_id}: {depart}->{arrive}")
        driver = None
        
        try:
            driver = self.setup_driver()
            overall_price, restricted_price = None, None
            overall_info, restricted_info = "", ""
            
            driver.get(url)
            WebDriverWait(driver, 40).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '[class^="inlineFilter_FilterWrapper__"]'))
            )
            time_module.sleep(5)
            items = driver.find_elements(By.XPATH, '//*[@id="international-content"]/div/div[3]/div')
            
            if not items:
                logger.warning(f"NO_ITEMS for {url}")
                raise NoFlightDataException("í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (NO_ITEMS)")

            found_any_price = False
            for item in items:
                text = item.text
                logger.debug(f"í•­ê³µê¶Œ ì •ë³´ í…ìŠ¤íŠ¸: {text}")
                
                if "ê²½ìœ " in text:
                    logger.debug("ê²½ìœ  í•­ê³µí¸ ì œì™¸")
                    continue
                    
                flight_info = parse_flight_info(text, depart, arrive)
                if not flight_info:
                    continue
                    
                dep_departure, dep_arrival, ret_departure, ret_arrival, price = flight_info
                found_any_price = True
                
                if overall_price is None or price < overall_price:
                    overall_price = price
                    overall_info = (
                        f"ê°€ëŠ” í¸: {dep_departure} â†’ {dep_arrival}\n"
                        f"ì˜¤ëŠ” í¸: {ret_departure} â†’ {ret_arrival}\n"
                        f"ì™•ë³µ ê°€ê²©: {price:,}ì›"
                    )
                    logger.debug(f"ì „ì²´ ìµœì €ê°€ ê°±ì‹ : {price:,}ì›")
                
                if check_time_restrictions(dep_departure, ret_departure, config):
                    if restricted_price is None or price < restricted_price:
                        restricted_price = price
                        restricted_info = (
                            f"ê°€ëŠ” í¸: {dep_departure} â†’ {dep_arrival}\n"
                            f"ì˜¤ëŠ” í¸: {ret_departure} â†’ {ret_arrival}\n"
                            f"ì™•ë³µ ê°€ê²©: {price:,}ì›"
                        )
                        logger.info(f"ì¡°ê±´ë¶€ ìµœì €ê°€ ê°±ì‹ : {price:,}ì›")

            if not found_any_price:
                logger.warning(f"NO_PRICES (found_any_price=False) for {url}")
                raise NoMatchingFlightsException("ì¡°ê±´ì— ë§ëŠ” í•­ê³µê¶Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (NO_PRICES_PARSED)")
            
            logger.info(f"Selenium ì‘ì—… ì™„ë£Œ #{task_id}")
            return restricted_price, restricted_info, overall_price, overall_info, url
            
        except Exception as e:
            logger.error(f"Selenium ì‘ì—… #{task_id} ì‹¤íŒ¨: {e}")
            raise
        finally:
            if driver:
                driver.quit()
            with self.lock:
                self.active_tasks -= 1

    async def fetch_prices_async(self, url: str, depart: str, arrive: str, config: dict) -> Tuple[Any, str, Any, str, str]:
        """ë¹„ë™ê¸° ê°€ê²© ì¡°íšŒ"""
        loop = asyncio.get_running_loop()
        
        try:
            result = await loop.run_in_executor(
                self.executor,
                self._fetch_single,
                url, depart, arrive, config
            )
            return result
        except Exception as e:
            logger.error(f"ë¹„ë™ê¸° fetch_prices ì‹¤íŒ¨: {e}")
            raise
    
    def shutdown(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("SeleniumManager ì¢…ë£Œ ì¤‘...")
        self.executor.shutdown(wait=True)

# ì „ì—­ Selenium ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
selenium_manager = SeleniumManager(
    max_workers=int(os.getenv("SELENIUM_WORKERS", "5")),
    grid_url=os.getenv("SELENIUM_HUB_URL", "http://localhost:4444/wd/hub"),
    user_agent=os.getenv("USER_AGENT")
)

# íŒŒì¼ ì‘ì—…ìš© executor
FILE_WORKERS = int(os.getenv("FILE_WORKERS", "5"))
file_executor = ThreadPoolExecutor(max_workers=FILE_WORKERS, thread_name_prefix="file")

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
DATA_DIR = Path("/data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

LOG_DIR = DATA_DIR / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = LOG_DIR / "flight_bot.log"

# ì‚¬ìš©ì ì„¤ì • ë””ë ‰í† ë¦¬
USER_CONFIG_DIR = DATA_DIR / "user_configs"
USER_CONFIG_DIR.mkdir(parents=True, exist_ok=True)

# ì‹œê°„ëŒ€ ì„¤ì •
TIME_PERIODS = {
    "ìƒˆë²½": (0, 6),    # 00:00 ~ 06:00
    "ì˜¤ì „1": (6, 9),   # 06:00 ~ 09:00
    "ì˜¤ì „2": (9, 12),  # 09:00 ~ 12:00
    "ì˜¤í›„1": (12, 15), # 12:00 ~ 15:00
    "ì˜¤í›„2": (15, 18), # 15:00 ~ 18:00
    "ë°¤1": (18, 21),   # 18:00 ~ 21:00
    "ë°¤2": (21, 24),   # 21:00 ~ 00:00
}

# ê¸°ë³¸ ì„¤ì •ê°’
DEFAULT_USER_CONFIG = {
    "time_type": "time_period",        # 'time_period' ë˜ëŠ” 'exact'
    "outbound_periods": ["ì˜¤ì „1", "ì˜¤ì „2"],  # ê°€ëŠ” í¸ ì‹œê°„ëŒ€
    "inbound_periods": ["ì˜¤í›„1", "ì˜¤í›„2", "ë°¤1"],  # ì˜¤ëŠ” í¸ ì‹œê°„ëŒ€
    "outbound_exact_hour": 9,          # ê°€ëŠ” í¸ ì‹œê° (ì‹œê°„ ë‹¨ìœ„)
    "inbound_exact_hour": 15,          # ì˜¤ëŠ” í¸ ì‹œê° (ì‹œê°„ ë‹¨ìœ„)
    "last_activity": None,             # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„
    "created_at": None                 # ì„¤ì • ìƒì„± ì‹œê°„
}

async def load_json_data_async(file_path: Path) -> dict:
    """ë¹„ë™ê¸° JSON ë°ì´í„° ë¡œë“œ"""
    loop = asyncio.get_running_loop()
    return await loop.run_in_executor(file_executor, load_json_data, file_path)

async def save_json_data_async(file_path: Path, data: dict):
    """ë¹„ë™ê¸° JSON ë°ì´í„° ì €ì¥"""
    loop = asyncio.get_running_loop()
    await loop.run_in_executor(file_executor, save_json_data, file_path, data)

async def get_user_config_async(user_id: int) -> dict:
    """ë¹„ë™ê¸° ì‚¬ìš©ì ì„¤ì • ë¡œë“œ"""
    config_file = USER_CONFIG_DIR / f"config_{user_id}.json"
    if config_file.exists():
        try:
            loop = asyncio.get_running_loop()
            data = await loop.run_in_executor(file_executor, lambda: get_user_config(user_id))
            return data
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    default_config = DEFAULT_USER_CONFIG.copy()
    default_config['created_at'] = format_datetime(datetime.now())
    default_config['last_activity'] = format_datetime(datetime.now())
    await loop.run_in_executor(file_executor, lambda: save_user_config(user_id, default_config))
    return default_config

def get_user_config(user_id: int) -> dict:
    """ì‚¬ìš©ì ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    config_file = USER_CONFIG_DIR / f"config_{user_id}.json"
    if config_file.exists():
        try:
            with file_lock(config_file):
                data = json.loads(config_file.read_text(encoding='utf-8'))
                # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
                data['last_activity'] = format_datetime(datetime.now())
                config_file.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')
                return data
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
    default_config = DEFAULT_USER_CONFIG.copy()
    default_config['created_at'] = format_datetime(datetime.now())
    default_config['last_activity'] = format_datetime(datetime.now())
    save_user_config(user_id, default_config)
    return default_config

def save_user_config(user_id: int, config: dict):
    """ì‚¬ìš©ì ì„¤ì •ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    config_file = USER_CONFIG_DIR / f"config_{user_id}.json"
    with file_lock(config_file):
        config_file.write_text(json.dumps(config, ensure_ascii=False, indent=2), encoding='utf-8')

def get_time_range(config: dict, direction: str) -> tuple[time, time]:
    """ì‹œê°„ ë²”ìœ„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        config: ì‚¬ìš©ì ì„¤ì •
        direction: 'outbound' ë˜ëŠ” 'inbound'
        
    Returns:
        tuple[time, time]: ì‹œì‘ ì‹œê°ê³¼ ì¢…ë£Œ ì‹œê°
    """
    if config['time_type'] == 'time_period':
        periods = config[f'{direction}_periods']
        period_ranges = [TIME_PERIODS[p] for p in periods]
        
        if direction == 'outbound':
            # ê°€ëŠ” í¸: ì„ íƒí•œ ì‹œê°„ëŒ€ë“¤ì˜ ê°ê°ì˜ ë²”ìœ„ë¥¼ ëª¨ë‘ ì²´í¬
            return None, None  # ì‹œê°„ëŒ€ëŠ” ê°œë³„ ì²´í¬í•˜ë„ë¡ None ë°˜í™˜
        else:
            # ì˜¤ëŠ” í¸: ì„ íƒí•œ ì‹œê°„ëŒ€ë“¤ì˜ ê°ê°ì˜ ë²”ìœ„ë¥¼ ëª¨ë‘ ì²´í¬
            return None, None  # ì‹œê°„ëŒ€ëŠ” ê°œë³„ ì²´í¬í•˜ë„ë¡ None ë°˜í™˜
    else:  # exact
        hour = config[f'{direction}_exact_hour']
        if direction == 'outbound':
            # ê°€ëŠ” í¸ì€ "ì´ì „"ì´ë¯€ë¡œ ì •í™•í•œ ì‹œê°ì´ ë ì‹œê°
            return time(hour=0, minute=0), time(hour=hour, minute=0)
        else:
            # ì˜¤ëŠ” í¸ì€ "ì´í›„"ì´ë¯€ë¡œ ì •í™•í•œ ì‹œê°ì´ ì‹œì‘ ì‹œê°
            return time(hour=hour, minute=0), time(hour=23, minute=59)

def format_time_range(config: dict, direction: str) -> str:
    """ì‹œê°„ ì„¤ì •ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if config['time_type'] == 'time_period':
        periods = config[f'{direction}_periods']
        period_ranges = [TIME_PERIODS[p] for p in periods]
        start_hours = [start for start, _ in period_ranges]
        end_hours = [end for _, end in period_ranges]
        period_str = ", ".join(periods)
        
        if direction == 'outbound':
            return f"{period_str} ({min(start_hours):02d}:00-{max(end_hours):02d}:00)"
        else:
            # ì˜¤ëŠ” í¸ì€ ì„ íƒí•œ ì‹œê°„ëŒ€ë“¤ì„ ëª¨ë‘ í‘œì‹œ
            time_ranges = [f"{start:02d}:00-{end:02d}:00" for start, end in period_ranges]
            return f"{period_str} ({' / '.join(time_ranges)})"
    else:  # exact
        hour = config[f'{direction}_exact_hour']
        return f"{hour:02d}:00 {'ì´ì „' if direction == 'outbound' else 'ì´í›„'}"

async def settings_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ì‚¬ìš©ì ì„¤ì • í™•ì¸ ë° ë³€ê²½"""
    user_id = update.effective_user.id
    config = await get_user_config_async(user_id)
    
    msg_lines = [
        "âš™ï¸ *ì‹œê°„ ì œí•œ ì„¤ì •*",
        "",
        "*í˜„ì¬ ì„¤ì •*",
        f"â€¢ ê°€ëŠ” í¸: {format_time_range(config, 'outbound')}",
        f"â€¢ ì˜¤ëŠ” í¸: {format_time_range(config, 'inbound')}",
        "",
        "*ì„¤ì • ë°©ë²•*",
        "1ï¸âƒ£ *ì‹œê°„ëŒ€ë¡œ ì„¤ì •* (í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í•­ê³µí¸ë§Œ ê²€ìƒ‰)",
        "â€¢ ê°€ëŠ” í¸: `/set ê°€ëŠ”í¸ ì‹œê°„ëŒ€ ì˜¤ì „1 ì˜¤ì „2`",
        "â€¢ ì˜¤ëŠ” í¸: `/set ì˜¤ëŠ”í¸ ì‹œê°„ëŒ€ ì˜¤í›„1 ì˜¤í›„2 ë°¤1`",
        "",
        "2ï¸âƒ£ *íŠ¹ì • ì‹œê°ìœ¼ë¡œ ì„¤ì •*",
        "â€¢ ê°€ëŠ” í¸: `/set ê°€ëŠ”í¸ ì‹œê° 9` (09:00 ì´ì „ ì¶œë°œ)",
        "â€¢ ì˜¤ëŠ” í¸: `/set ì˜¤ëŠ”í¸ ì‹œê° 15` (15:00 ì´í›„ ì¶œë°œ)",
        "",
        "*ì‹œê°„ëŒ€ êµ¬ë¶„*",
        "â€¢ ìƒˆë²½ (00-06), ì˜¤ì „1 (06-09)",
        "â€¢ ì˜¤ì „2 (09-12), ì˜¤í›„1 (12-15)",
        "â€¢ ì˜¤í›„2 (15-18), ë°¤1 (18-21)",
        "â€¢ ë°¤2 (21-24)"
    ]
    
    # ê´€ë¦¬ì ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ í‚¤ë³´ë“œ í‘œì‹œ
    keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown",
        reply_markup=keyboard
    )

async def set_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ì„¤ì • ë³€ê²½"""
    user_id = update.effective_user.id
    args = update.message.text.strip().split()
    
    if len(args) < 4:
        await update.message.reply_text(
            "â— ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n"
            "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        return
    
    _, direction, set_type, *values = args
    
    if direction not in ["ê°€ëŠ”í¸", "ì˜¤ëŠ”í¸"]:
        await update.message.reply_text("â— 'ê°€ëŠ”í¸' ë˜ëŠ” 'ì˜¤ëŠ”í¸'ë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return
    
    direction = "outbound" if direction == "ê°€ëŠ”í¸" else "inbound"
    config = await get_user_config_async(user_id)
    
    if set_type == "ì‹œê°":
        if len(values) != 1 or not values[0].isdigit():
            await update.message.reply_text("â— ì‹œê°ì€ 0-23 ì‚¬ì´ì˜ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        hour = int(values[0])
        if hour < 0 or hour > 23:
            await update.message.reply_text("â— ì‹œê°ì€ 0-23 ì‚¬ì´ì˜ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        config['time_type'] = 'exact'
        config[f'{direction}_exact_hour'] = hour
        
    elif set_type == "ì‹œê°„ëŒ€":
        if not values:
            await update.message.reply_text("â— í•˜ë‚˜ ì´ìƒì˜ ì‹œê°„ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
            
        invalid_periods = [p for p in values if p not in TIME_PERIODS]
        if invalid_periods:
            await update.message.reply_text(
                f"â— ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì‹œê°„ëŒ€: {', '.join(invalid_periods)}\n"
                "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            return
            
        config['time_type'] = 'time_period'
        config[f'{direction}_periods'] = values
        
    else:
        await update.message.reply_text(
            "â— 'ì‹œê°' ë˜ëŠ” 'ì‹œê°„ëŒ€'ë¡œë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
            "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        return
    
    await save_user_config_async(user_id, config)
    await update.message.reply_text(
        f"âœ… {direction=='outbound'and'ê°€ëŠ” í¸'or'ì˜¤ëŠ” í¸'} ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤:\n"
        f"{format_time_range(config, direction)}"
    )

# ë¡œê·¸ íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
MAX_LOG_SIZE = 10 * 1024 * 1024

def rotate_logs():
    """ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜"""
    if not LOG_FILE.exists() or LOG_FILE.stat().st_size < MAX_LOG_SIZE:
        return
    
    for i in range(4, 0, -1):
        old = LOG_FILE.with_suffix(f'.log.{i}')
        new = LOG_FILE.with_suffix(f'.log.{i+1}')
        if old.exists():
            old.rename(new)
    if LOG_FILE.exists():
        LOG_FILE.rename(LOG_FILE.with_suffix('.log.1'))

rotate_logs()
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-7s | %(name)s | %(filename)s:%(lineno)d | %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    logger.error("í™˜ê²½ë³€ìˆ˜ BOT_TOKENì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    raise RuntimeError("BOT_TOKENì´ í•„ìš”í•©ë‹ˆë‹¤.")

SELENIUM_HUB_URL = os.getenv("SELENIUM_HUB_URL", "http://localhost:4444/wd/hub")
USER_AGENT = os.getenv(
    "USER_AGENT",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36"
)
# ì‚¬ìš©ìë‹¹ ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜
MAX_MONITORS = int(os.getenv("MAX_MONITORS", "3"))

raw_admin = os.getenv("ADMIN_IDS", "")
ADMIN_IDS = set(int(p.strip()) for p in raw_admin.split(",") if p.strip().isdigit())

KST = ZoneInfo("Asia/Seoul")
SETTING = 1

# íŒŒì¼ íŒ¨í„´
PATTERN = re.compile(
    r"price_(?P<uid>\d+)_(?P<dep>[A-Z]{3})_(?P<arr>[A-Z]{3})_(?P<dd>\d{8})_(?P<rd>\d{8})\.json"
)

def format_datetime(dt: datetime) -> str:
    return dt.astimezone(KST).strftime('%Y-%m-%d %H:%M:%S')

def setup_selenium_driver():
    """Selenium WebDriver ì„¤ì •"""
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument(f"user-agent={USER_AGENT}")
    return webdriver.Remote(
        command_executor=SELENIUM_HUB_URL,
        options=options
    )

def parse_flight_info(text: str, depart: str, arrive: str) -> tuple[str, str, str, str, int] | None:
    """í•­ê³µí¸ ì •ë³´ íŒŒì‹±
    Returns:
        tuple[str, str, str, str, int] | None: (ì¶œë°œì‹œê°, ë„ì°©ì‹œê°, ê·€êµ­ì¶œë°œì‹œê°, ê·€êµ­ë„ì°©ì‹œê°, ê°€ê²©)
    """
    # ê°€ëŠ” í¸: ì¶œë°œì§€ì—ì„œ ë„ì°©ì§€ë¡œ ê°€ëŠ” í•­ê³µí¸
    m_dep = re.search(rf'(\d{{2}}:\d{{2}}){depart}\s+(\d{{2}}:\d{{2}}){arrive}', text, re.IGNORECASE)
    if not m_dep:
        return None
        
    # ì˜¤ëŠ” í¸: ë„ì°©ì§€ì—ì„œ ì¶œë°œì§€ë¡œ ì˜¤ëŠ” í•­ê³µí¸
    m_ret = re.search(rf'(\d{{2}}:\d{{2}}){arrive}\s+(\d{{2}}:\d{{2}}){depart}', text, re.IGNORECASE)
    if not m_ret:
        return None
        
    # ê°€ê²© ì •ë³´
    m_price = re.search(r'ì™•ë³µ\s*([\d,]+)ì›', text)
    if not m_price:
        return None
        
    price = int(m_price.group(1).replace(",", ""))
    return (
        m_dep.group(1),  # ì¶œë°œì‹œê°
        m_dep.group(2),  # ë„ì°©ì‹œê°
        m_ret.group(1),  # ê·€êµ­ì¶œë°œì‹œê°
        m_ret.group(2),  # ê·€êµ­ë„ì°©ì‹œê°
        price           # ê°€ê²©
    )

def check_time_restrictions(dep_time: str, ret_time: str, config: dict) -> bool:
    """ì‹œê°„ ì œí•œ ì¡°ê±´ ì²´í¬
    Returns:
        bool: ì‹œê°„ ì œí•œ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€
    """
    dep_t = datetime.strptime(dep_time, "%H:%M").time()
    ret_t = datetime.strptime(ret_time, "%H:%M").time()
    
    if config['time_type'] == 'time_period':
        # ì‹œê°„ëŒ€ ì„¤ì •: ì„ íƒëœ ì‹œê°„ëŒ€ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ìœ íš¨
        outbound_periods = config['outbound_periods']
        inbound_periods = config['inbound_periods']
        
        # ê°€ëŠ” í¸: ì„ íƒëœ ì‹œê°„ëŒ€ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ìœ íš¨
        is_valid_outbound = any(
            period_start <= dep_t.hour < period_end
            for period in outbound_periods
            for period_start, period_end in [TIME_PERIODS[period]]
        )
        if not is_valid_outbound:
            logger.debug(f"ê°€ëŠ” í¸ ì‹œê°„ëŒ€ ë¯¸ë§¤ì¹­: {dep_t}ëŠ” ì„ íƒëœ ì‹œê°„ëŒ€ {outbound_periods}ì— í¬í•¨ë˜ì§€ ì•ŠìŒ")
            return False
            
        # ì˜¤ëŠ” í¸: ì„ íƒëœ ì‹œê°„ëŒ€ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ìœ íš¨
        is_valid_inbound = any(
            period_start <= ret_t.hour < period_end
            for period in inbound_periods
            for period_start, period_end in [TIME_PERIODS[period]]
        )
        if not is_valid_inbound:
            logger.debug(f"ì˜¤ëŠ” í¸ ì‹œê°„ëŒ€ ë¯¸ë§¤ì¹­: {ret_t}ëŠ” ì„ íƒëœ ì‹œê°„ëŒ€ {inbound_periods}ì— í¬í•¨ë˜ì§€ ì•ŠìŒ")
            return False
            
    else:  # exact
        # ì‹œê° ì„¤ì •: ê°€ëŠ” í¸ì€ ì„¤ì • ì‹œê° ì´ì „, ì˜¤ëŠ” í¸ì€ ì„¤ì • ì‹œê° ì´í›„
        outbound_limit = time(hour=config['outbound_exact_hour'], minute=0)
        if dep_t > outbound_limit:
            logger.debug(f"ê°€ëŠ” í¸ ì‹œê° ë¯¸ë§¤ì¹­: {dep_t} > {outbound_limit}")
            return False
            
        inbound_limit = time(hour=config['inbound_exact_hour'], minute=0)
        if ret_t < inbound_limit:
            logger.debug(f"ì˜¤ëŠ” í¸ ì‹œê° ë¯¸ë§¤ì¹­: {ret_t} < {inbound_limit}")
            return False
            
    return True

# Custom Exceptions (defined globally)
class NoFlightDataException(Exception):
    """í•­ê³µê¶Œ ì •ë³´ë¥¼ í¬ë¡¤ë§í•  ìˆ˜ ì—†ì„ ë•Œ ë°œìƒ"""
    pass

class NoMatchingFlightsException(Exception):
    """ì¡°ê±´ì— ë§ëŠ” í•­ê³µê¶Œì„ ì°¾ì„ ìˆ˜ ì—†ì„ ë•Œ ë°œìƒ"""
    pass

# Modified fetch_prices to raise custom exceptions
async def fetch_prices(depart: str, arrive: str, d_date: str, r_date: str, max_retries=3, user_id=None):
    """í•­ê³µê¶Œ ê°€ê²© ì¡°íšŒ (ë¹„ë™ê¸° ì²˜ë¦¬)"""
    logger.info(f"fetch_prices í˜¸ì¶œ: {depart}->{arrive} {d_date}~{r_date} (User: {user_id})")
    url = (
        f"https://flight.naver.com/flights/international/"
        f"{depart}-{arrive}-{d_date}/{arrive}-{depart}-{r_date}?adult=1&fareType=Y"
    )
    config = await get_user_config_async(user_id) if user_id else DEFAULT_USER_CONFIG.copy()
    
    async def _fetch_with_retry():
        last_exception = None
        for attempt in range(max_retries):
            try:
                logger.info(f"ì‹œë„ {attempt + 1}/{max_retries}: {depart}->{arrive}")
                
                # ì „ì—­ selenium_manager ì‚¬ìš©
                result = await selenium_manager.fetch_prices_async(url, depart, arrive, config)
                
                logger.info(f"ì¡°íšŒ ì„±ê³µ: {depart}->{arrive} (ì‹œë„ {attempt + 1})")
                return result
                
            except (NoFlightDataException, NoMatchingFlightsException) as e:
                last_exception = e
                logger.warning(f"fetch_prices ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨ (Specific): {e}")
                if attempt == max_retries - 1:
                    raise
            except Exception as ex:
                last_exception = ex
                logger.warning(f"fetch_prices ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨ (Generic): {ex}", exc_info=True)
                if attempt == max_retries - 1:
                    raise Exception(f"í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {ex}") from ex
                
                wait_time = 5 * (attempt + 1)
                logger.info(f"{wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                await asyncio.sleep(wait_time)
        
        if last_exception:
            raise last_exception
        raise Exception("í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ë¡œ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨")

    return await _fetch_with_retry()

# ë„ì›€ë§ í…ìŠ¤íŠ¸
async def help_text(user_id: int = None) -> str:
    admin_help = ""
    if ADMIN_IDS and user_id in ADMIN_IDS:
        admin_help = (
            "\n\nğŸ‘‘ *ê´€ë¦¬ì ëª…ë ¹ì–´*\n"
            "â€¢ /allstatus - ì „ì²´ ëª¨ë‹ˆí„°ë§ í˜„í™©\n"
            "â€¢ /allcancel - ì „ì²´ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ"
        )
    
    return (
        "âœˆï¸ *í•­ê³µê¶Œ ìµœì €ê°€ ëª¨ë‹ˆí„°ë§ ë´‡*\n"
        "\n"
        "ğŸ“ *ê¸°ë³¸ ëª…ë ¹ì–´*\n"
        "â€¢ /monitor - ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ ì‹œì‘\n"
        "â€¢ /status - ëª¨ë‹ˆí„°ë§ í˜„í™© í™•ì¸\n"
        "â€¢ /cancel - ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ\n"
        "\n"
        "âš™ï¸ *ì„¤ì • ëª…ë ¹ì–´*\n"
        "â€¢ /settings - ì‹œê°„ ì œí•œ ì„¤ì •\n"
        "â€¢ /airport - ê³µí•­ ì½”ë“œ ëª©ë¡"
        + admin_help
    )

def get_base_keyboard() -> ReplyKeyboardMarkup:
    """ê¸°ë³¸ í‚¤ë³´ë“œ ë²„íŠ¼ ìƒì„±"""
    keyboard = [
        [KeyboardButton("/monitor"), KeyboardButton("/status")],
        [KeyboardButton("/settings"), KeyboardButton("/airport")],
        [KeyboardButton("/cancel"), KeyboardButton("/help")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

def get_admin_keyboard() -> ReplyKeyboardMarkup:
    """ê´€ë¦¬ììš© í‚¤ë³´ë“œ ë²„íŠ¼ ìƒì„±"""
    keyboard = [
        [KeyboardButton("/monitor"), KeyboardButton("/status")],
        [KeyboardButton("/settings"), KeyboardButton("/airport")],
        [KeyboardButton("/cancel"), KeyboardButton("/help")],
        [KeyboardButton("/allstatus"), KeyboardButton("/allcancel")]
    ]
    return ReplyKeyboardMarkup(keyboard, resize_keyboard=True)

async def start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /start")
    # ê´€ë¦¬ì ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ í‚¤ë³´ë“œ í‘œì‹œ
    keyboard = get_admin_keyboard() if update.effective_user.id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        await help_text(update.effective_user.id),
        parse_mode="Markdown",
        reply_markup=keyboard
    )

async def help_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /help")
    # ê´€ë¦¬ì ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥¸ í‚¤ë³´ë“œ í‘œì‹œ
    keyboard = get_admin_keyboard() if update.effective_user.id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        await help_text(update.effective_user.id),
        parse_mode="Markdown",
        reply_markup=keyboard
    )

def validate_url(url: str) -> tuple[bool, str]:
    """URL ìœ íš¨ì„± ê²€ì‚¬
    Returns:
        tuple[bool, str]: (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    try:
        result = urlparse(url)
        if not all([result.scheme, result.netloc]):
            return False, "URL í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤"
        if result.scheme not in ["http", "https"]:
            return False, "URLì€ http ë˜ëŠ” httpsë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤"
        return True, ""
    except Exception:
        return False, "URL íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"

def validate_env_vars() -> list[str]:
    """í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    Returns:
        list[str]: ì˜¤ë¥˜ ë©”ì‹œì§€ ëª©ë¡
    """
    errors = []
    
    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜
    if not os.getenv("BOT_TOKEN"):
        errors.append("BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
    # Selenium Hub URL ê²€ì¦
    selenium_url = os.getenv("SELENIUM_HUB_URL", "http://localhost:4444/wd/hub")
    is_valid, error_msg = validate_url(selenium_url)
    if not is_valid:
        errors.append(f"SELENIUM_HUB_URLì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {error_msg}")
        
    # ê´€ë¦¬ì ID ê²€ì¦
    admin_ids = os.getenv("ADMIN_IDS", "")
    if admin_ids:
        for admin_id in admin_ids.split(","):
            if admin_id.strip() and not admin_id.strip().isdigit():
                errors.append(f"ADMIN_IDSì— ì˜¬ë°”ë¥´ì§€ ì•Šì€ IDê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤: {admin_id}")
        
    # ìˆ«ìí˜• í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    for var_name, default, min_val in [
        ("MAX_MONITORS", "3", 1),
        ("DATA_RETENTION_DAYS", "30", 1),
        ("CONFIG_RETENTION_DAYS", "7", 1)
    ]:
        try:
            value = int(os.getenv(var_name, default))
            if value < min_val:
                errors.append(f"{var_name}ëŠ” {min_val} ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
        except ValueError:
            errors.append(f"{var_name}ê°€ ì˜¬ë°”ë¥¸ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤")
        
    return errors

# ëª…ë ¹ì–´ ì†ë„ ì œí•œ
class RateLimiter:
    def __init__(self, max_calls: int, time_window: float):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = defaultdict(list)
        
    def is_allowed(self, user_id: int) -> bool:
        """ì‚¬ìš©ìì˜ ëª…ë ¹ì–´ ì‹¤í–‰ í—ˆìš© ì—¬ë¶€ í™•ì¸"""
        now = time_module.time()
        user_calls = self.calls[user_id]
        
        # ì‹œê°„ ì°½ ë°–ì˜ ê¸°ë¡ ì œê±°
        while user_calls and now - user_calls[0] > self.time_window:
            user_calls.pop(0)
            
        if len(user_calls) >= self.max_calls:
            return False
            
        user_calls.append(now)
        return True

# ì†ë„ ì œí•œ ì„¤ì • (1ë¶„ì— 10íšŒ)
rate_limiter = RateLimiter(max_calls=10, time_window=60)

def rate_limit(func):
    """ëª…ë ¹ì–´ ì†ë„ ì œí•œ ë°ì½”ë ˆì´í„°"""
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        
        if not rate_limiter.is_allowed(user_id):
            await update.message.reply_text(
                "â— ë„ˆë¬´ ë§ì€ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
            return
            
        return await func(update, context)
    return wrapper

@rate_limit
async def monitor_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ì‚¬ìš©ì {user_id} ìš”ì²­: /monitor")
    
    # í˜„ì¬ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ í™•ì¸
    existing = [p for p in DATA_DIR.iterdir() if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id]
    if len(existing) >= MAX_MONITORS:
        logger.warning(f"ì‚¬ìš©ì {user_id} ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ì´ˆê³¼")
        keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
        await update.message.reply_text(
            f"â— ìµœëŒ€ {MAX_MONITORS}ê°œê¹Œì§€ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ì„ ì¶”ê°€í•˜ë ¤ë©´ ë¨¼ì € ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ì„ ì·¨ì†Œí•´ì£¼ì„¸ìš”.",
            reply_markup=keyboard
        )
        return ConversationHandler.END

    msg_lines = [
        "âœˆï¸ *í•­ê³µê¶Œ ëª¨ë‹ˆí„°ë§ ì„¤ì •*",
        "",
        "ì¶œë°œê³µí•­ ë„ì°©ê³µí•­ ê°€ëŠ”ë‚ ì§œ ì˜¤ëŠ”ë‚ ì§œ",
        "ì˜ˆì‹œ: `ICN FUK 20251025 20251027`",
        "",
        "â€¢ ê³µí•­ì½”ë“œ: 3ìë¦¬ ì˜ë¬¸",
        "â€¢ ë‚ ì§œ: YYYYMMDD"
    ]
    # ëª¨ë‹ˆí„°ë§ ì„¤ì • ì‹œì—ëŠ” í‚¤ë³´ë“œ ìˆ¨ê¸°ê¸°
    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown",
        reply_markup=ReplyKeyboardRemove()
    )
    return SETTING

# ìœ íš¨ ë‚ ì§œ ì²´í¬
from datetime import datetime as _dt

def valid_date(d: str) -> tuple[bool, str]:
    """ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
    Returns:
        (bool, str): (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    try:
        date = _dt.strptime(d, "%Y%m%d")
        now = _dt.now()
        
        # ê³¼ê±° ë‚ ì§œ ì²´í¬
        if date.date() < now.date():
            return False, "ê³¼ê±° ë‚ ì§œëŠ” ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
        # 1ë…„ ì´ìƒ ë¯¸ë˜ ì²´í¬
        max_future = now.replace(year=now.year + 1)
        if date > max_future:
            return False, "1ë…„ ì´ìƒ ë¯¸ë˜ì˜ ë‚ ì§œëŠ” ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
        return True, ""
    except ValueError:
        return False, "ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤ (YYYYMMDD)"

# ê³µí•­ ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬
def load_airports():
    """ê³µí•­ ë°ì´í„° ë¡œë“œ"""
    airports_file = Path("/app/data/airports.json")
    if not airports_file.exists():
        logger.error("ê³µí•­ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: airports.json")
        raise FileNotFoundError("airports.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
    try:
        with open(airports_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"ê³µí•­ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

# ê³µí•­ ë°ì´í„° ë¡œë“œ
try:
    AIRPORTS = load_airports()
except Exception as e:
    logger.error(f"ê³µí•­ ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    sys.exit(1)

def get_airport_info(code: str) -> tuple[bool, str, str]:
    """ê³µí•­ ì½”ë“œì˜ ìœ íš¨ì„±ê³¼ ì •ë³´ë¥¼ ë°˜í™˜
    Returns:
        tuple[bool, str, str]: (ìœ íš¨ì„± ì—¬ë¶€, ë„ì‹œëª…, ê³µí•­ëª…)
    """
    code = code.upper()
    for region_data in AIRPORTS.values():
        airports = region_data.get('airports', {})
        if code in airports:
            city, airport = airports[code]
            return True, city, airport
    return False, "", ""

def format_airport_list() -> str:
    """ìì£¼ ê°€ëŠ” ê³µí•­ ëª©ë¡ì„ í¬ë§¤íŒ…"""
    lines = [
        "âœˆï¸ *ìì£¼ ì°¾ëŠ” ê³µí•­ ì½”ë“œ*",
        "",
        "*í•œêµ­*",
        "â€¢ `ICN`: ì¸ì²œ (ì„œìš¸/ì¸ì²œêµ­ì œê³µí•­)",
        "â€¢ `GMP`: ê¹€í¬ (ì„œìš¸/ê¹€í¬êµ­ì œê³µí•­)",
        "â€¢ `PUS`: ë¶€ì‚° (ë¶€ì‚°/ê¹€í•´êµ­ì œê³µí•­)",
        "â€¢ `CJU`: ì œì£¼ (ì œì£¼êµ­ì œê³µí•­)",
        "",
        "*ì¼ë³¸*",
        "â€¢ `NRT`: ë‚˜ë¦¬íƒ€ (ë„ì¿„/ë‚˜ë¦¬íƒ€êµ­ì œê³µí•­)",
        "â€¢ `HND`: í•˜ë„¤ë‹¤ (ë„ì¿„/í•˜ë„¤ë‹¤êµ­ì œê³µí•­)",
        "â€¢ `KIX`: ê°„ì‚¬ì´ (ì˜¤ì‚¬ì¹´/ê°„ì‚¬ì´êµ­ì œê³µí•­)",
        "â€¢ `FUK`: í›„ì¿ ì˜¤ì¹´ (í›„ì¿ ì˜¤ì¹´êµ­ì œê³µí•­)",
        "",
        "*ë™ë‚¨ì•„ì‹œì•„*",
        "â€¢ `BKK`: ë°©ì½• (ìˆ˜ì™„ë‚˜í’ˆêµ­ì œê³µí•­)",
        "â€¢ `SGN`: í˜¸ì¹˜ë¯¼ (ë–¤ì„ ë…“êµ­ì œê³µí•­)",
        "â€¢ `MNL`: ë§ˆë‹ë¼ (ë‹ˆë…¸ì´ ì•„í‚¤ë…¸êµ­ì œê³µí•­)",
        "â€¢ `SIN`: ì‹±ê°€í¬ë¥´ (ì°½ì´êµ­ì œê³µí•­)",
        "",
        "ğŸ’¡ ë” ë§ì€ ê³µí•­ ì½”ë“œëŠ” ì•„ë˜ ë§í¬ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:",
        "[í•­ê³µì •ë³´í¬í„¸ì‹œìŠ¤í…œ](https://www.airportal.go.kr/airport/airport.do)"
    ]
    return "\n".join(lines)

def valid_airport(code: str) -> tuple[bool, str]:
    """ê³µí•­ ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬ (ê¸°ë³¸ í˜•ì‹ë§Œ ê²€ì‚¬)
    Returns:
        (bool, str): (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    if not code.isalpha() or len(code) != 3:
        return False, "ê³µí•­ ì½”ë“œëŠ” 3ìë¦¬ ì˜ë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤"
    
    code = code.upper()
    is_valid, city, airport = get_airport_info(code)
    
    # ì•Œë ¤ì§„ ê³µí•­ì´ ì•„ë‹ˆë”ë¼ë„ í˜•ì‹ì´ ë§ìœ¼ë©´ ì¼ë‹¨ í—ˆìš©
    # ì‹¤ì œ ìœ íš¨ì„±ì€ í•­ê³µê¶Œ ì¡°íšŒ ì‹œ í™•ì¸ë¨
    return True, ""

# New cancel_conversation function
async def cancel_conversation(update: Update, context: ContextTypes.DEFAULT_TYPE) -> int:
    """Cancels and ends the current conversation."""
    user_id = update.effective_user.id
    logger.info(f"User {user_id} canceled the conversation.")
    keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        'ì§„í–‰ ì¤‘ì´ë˜ ì„¤ì • ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.', reply_markup=keyboard
    )
    return ConversationHandler.END

# Modified monitor_setting function for better flow
async def monitor_setting(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    final_keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
    text = update.message.text.strip().split()

    if len(text) != 4:
        logger.warning(f"monitor_setting ({user_id}): í˜•ì‹ ì˜¤ë¥˜ - {text}")
        await update.message.reply_text(
            "â— í˜•ì‹ ì˜¤ë¥˜\n"
            "âœ… ì˜¬ë°”ë¥¸ í˜•ì‹: `ICN FUK 20251025 20251027`\n"
            "- ê³µí•­ì½”ë“œ: 3ìë¦¬ ì˜ë¬¸\n"
            "- ë‚ ì§œ: YYYYMMDD\n\n"
            "ğŸ’¡ ì£¼ìš” ê³µí•­ ì½”ë“œ ëª©ë¡ì€ /airport ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "ë‹¤ì‹œ ì…ë ¥í•˜ì‹œê±°ë‚˜ /cancel ëª…ë ¹ìœ¼ë¡œ ì·¨ì†Œí•˜ì„¸ìš”.",
            parse_mode="Markdown"
        )
        return SETTING

    outbound_dep, outbound_arr, outbound_date, inbound_date = text
    outbound_dep = outbound_dep.upper()
    outbound_arr = outbound_arr.upper()

    # ì´ˆê¸° ìƒíƒœ ë©”ì‹œì§€ ìƒì„±
    status_message = await update.message.reply_text(
        "ğŸ” í•­ê³µê¶Œ ì •ë³´ë¥¼ ì¡°íšŒí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤...\nâ³ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.",
        reply_markup=None
    )
    
    # ë©”ì‹œì§€ ë§¤ë‹ˆì €ì— ë“±ë¡
    message_manager.set_status_message(user_id, status_message)
    
    try:
        # ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ í™•ì¸
        loop = asyncio.get_running_loop()
        existing = await loop.run_in_executor(
            file_executor,
            lambda: [p for p in DATA_DIR.iterdir() 
                    if PATTERN.fullmatch(p.name) and 
                    int(PATTERN.fullmatch(p.name).group('uid')) == user_id]
        )
        
        if len(existing) >= MAX_MONITORS:
            logger.warning(f"ì‚¬ìš©ì {user_id} ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ì´ˆê³¼")
            await message_manager.update_status_message(
                user_id,
                f"â— ìµœëŒ€ {MAX_MONITORS}ê°œê¹Œì§€ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                reply_markup=final_keyboard
            )
            return ConversationHandler.END

        # ê³µí•­ ì •ë³´ í™•ì¸
        _, dep_city, dep_airport = get_airport_info(outbound_dep)
        _, arr_city, arr_airport = get_airport_info(outbound_arr)
        dep_city = dep_city or outbound_dep
        dep_airport = dep_airport or f"{outbound_dep}ê³µí•­"
        arr_city = arr_city or outbound_arr
        arr_airport = arr_airport or f"{outbound_arr}ê³µí•­"

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        await message_manager.update_status_message(
            user_id,
            f"ğŸ” {dep_city} â†’ {arr_city} í•­ê³µê¶Œ ì¡°íšŒ ì¤‘...\nâ³ ë„¤ì´ë²„ í•­ê³µê¶Œì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  ìˆìŠµë‹ˆë‹¤."
        )
        
        # ê°€ê²© ì¡°íšŒ (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…)
        try:
            restricted, r_info, overall, o_info, link = await fetch_prices(
                outbound_dep, outbound_arr, outbound_date, inbound_date, 3, user_id
            )
            
            if restricted is None and overall is None:
                raise NoFlightDataException("í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²°ê³¼ ì—†ìŒ)")
            
        except Exception as fetch_error:
            logger.error(f"ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨ (User: {user_id}): {fetch_error}")
            await message_manager.update_status_message(
                user_id,
                f"âŒ í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\nğŸ”¸ {str(fetch_error)}\n\në‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
                reply_markup=final_keyboard
            )
            return ConversationHandler.END
        
        # ëª¨ë‹ˆí„°ë§ ì„¤ì • ì €ì¥
        hist_path = DATA_DIR / f"price_{user_id}_{outbound_dep}_{outbound_arr}_{outbound_date}_{inbound_date}.json"
        start_time = format_datetime(datetime.now())
        user_config = await get_user_config_async(user_id)
        
        await save_json_data_async(hist_path, {
            "start_time": start_time,
            "restricted": restricted or 0,
            "overall": overall or 0,
            "last_fetch": format_datetime(datetime.now()),
            "time_setting_outbound": format_time_range(user_config, 'outbound'),
            "time_setting_inbound": format_time_range(user_config, 'inbound')
        })

        # ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬ ë“±ë¡
        job = ctx.application.job_queue.run_repeating(
            monitor_job, 
            interval=timedelta(minutes=30), 
            first=timedelta(seconds=0),
            name=str(hist_path), 
            data={
                "chat_id": user_id, 
                "settings": (outbound_dep, outbound_arr, outbound_date, inbound_date),
                "hist_path": str(hist_path)
            }
        )

        monitors = ctx.application.bot_data.setdefault("monitors", {})
        monitors.setdefault(user_id, []).append({
            "settings": (outbound_dep, outbound_arr, outbound_date, inbound_date),
            "start_time": datetime.now(KST),
            "hist_path": str(hist_path),
            "job": job
        })

        logger.info(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘ ë“±ë¡: {hist_path}")
        
        # ìµœì¢… ì„±ê³µ ë©”ì‹œì§€
        msg_lines = [
            f"âœ… *{dep_city} â†” {arr_city} ëª¨ë‹ˆí„°ë§ ì‹œì‘*",
            f"ğŸ›« ê°€ëŠ” í¸: {dep_airport} â†’ {arr_airport}",
            f"ğŸ›¬ ì˜¤ëŠ” í¸: {arr_airport} â†’ {dep_airport}",
            f"ğŸ“… {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}",
            "",
            "âš™ï¸ *ì ìš©ëœ ì‹œê°„ ì œí•œ*",
            f"â€¢ ê°€ëŠ” í¸: {format_time_range(user_config, 'outbound')}",
            f"â€¢ ì˜¤ëŠ” í¸: {format_time_range(user_config, 'inbound')}",
            "",
            "ğŸ“Š *í˜„ì¬ ìµœì €ê°€*"
        ]
        
        if restricted:
            msg_lines.extend([f"ğŸ¯ *ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€*", r_info, ""])
        if overall:
            msg_lines.extend([f"ğŸ“Œ *ì „ì²´ ìµœì €ê°€*", o_info])
            
        msg_lines.extend([
            "", "â„¹ï¸ 30ë¶„ë§ˆë‹¤ ìë™ìœ¼ë¡œ ê°€ê²©ì„ í™•ì¸í•˜ë©°,", 
            "ê°€ê²©ì´ í•˜ë½í•˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.",
            "", f"ğŸ”— [ë„¤ì´ë²„ í•­ê³µê¶Œ ë°”ë¡œê°€ê¸°]({link})"
        ])
        
        # ìµœì¢… ê²°ê³¼ ì—…ë°ì´íŠ¸
        final_result = await message_manager.update_status_message(
            user_id,
            "\n".join(msg_lines),
            parse_mode="Markdown",
            reply_markup=final_keyboard
        )
        
        if not final_result:
            # í¸ì§‘ ì‹¤íŒ¨ ì‹œ ìƒˆ ë©”ì‹œì§€ ë°œì†¡
            await update.message.reply_text(
                "\n".join(msg_lines),
                parse_mode="Markdown",
                disable_web_page_preview=True,
                reply_markup=final_keyboard
            )
        
    except Exception as e:
        logger.error(f"monitor_setting ì „ì²´ ì‹¤íŒ¨ (User: {user_id}): {e}")
        await message_manager.update_status_message(
            user_id,
            f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n{str(e)}",
            reply_markup=final_keyboard
        )
    
    finally:
        # ìƒíƒœ ë©”ì‹œì§€ ì •ë¦¬
        message_manager.clear_status_message(user_id)
    
    return ConversationHandler.END

async def run_fetch_prices(status_message, dep, arr, d_date, r_date, user_id, ctx):
    final_keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()

    try:
        restricted, r_info, overall, o_info, link = await fetch_prices(dep, arr, d_date, r_date, 3, user_id)
        if restricted is None and overall is None:
            raise NoFlightDataException("í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²°ê³¼ ì—†ìŒ)")
        hist_path = DATA_DIR / f"price_{user_id}_{dep}_{arr}_{d_date}_{r_date}.json"
        user_config = await get_user_config_async(user_id)
        await save_json_data_async(hist_path, {
            "start_time": format_datetime(datetime.now()),
            "restricted": restricted or 0,
            "overall": overall or 0,
            "last_fetch": format_datetime(datetime.now()),
            "time_setting_outbound": format_time_range(user_config, 'outbound'),
            "time_setting_inbound": format_time_range(user_config, 'inbound')
        })

        job = ctx.application.job_queue.run_repeating(
            monitor_job, interval=timedelta(minutes=30), first=timedelta(seconds=0),
            name=str(hist_path), data={
                "chat_id": user_id, "settings": (dep, arr, d_date, r_date),
                "hist_path": str(hist_path)
            }
        )

        monitors = ctx.application.bot_data.setdefault("monitors", {})
        monitors.setdefault(user_id, []).append({
            "settings": (dep, arr, d_date, r_date),
            "start_time": datetime.now(KST),
            "hist_path": str(hist_path),
            "job": job
        })

        _, dep_city, dep_airport = get_airport_info(dep)
        _, arr_city, arr_airport = get_airport_info(arr)
        dep_city = dep_city or dep
        arr_city = arr_city or arr

        logger.info(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘ ë“±ë¡: {hist_path}")

        msg_lines = [
            f"âœ… *{dep_city} â†” {arr_city} ëª¨ë‹ˆí„°ë§ ì‹œì‘*",
            f"ğŸ›« ê°€ëŠ” í¸: {dep_airport} â†’ {arr_airport}",
            f"ğŸ›¬ ì˜¤ëŠ” í¸: {arr_airport} â†’ {dep_airport}",
            f"ğŸ“… {d_date[:4]}/{d_date[4:6]}/{d_date[6:]} â†’ {r_date[:4]}/{r_date[4:6]}/{r_date[6:]}",
            "",
            "âš™ï¸ *ì ìš©ëœ ì‹œê°„ ì œí•œ*",
            f"â€¢ ê°€ëŠ” í¸: {format_time_range(user_config, 'outbound')}",
            f"â€¢ ì˜¤ëŠ” í¸: {format_time_range(user_config, 'inbound')}",
            "",
            "ğŸ“Š *í˜„ì¬ ìµœì €ê°€*"
        ]

        if restricted:
            msg_lines.extend(["ğŸ¯ *ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€*", r_info, ""])
        if overall:
            msg_lines.extend(["ğŸ“Œ *ì „ì²´ ìµœì €ê°€*", o_info])
            
        msg_lines.extend([
            "", "â„¹ï¸ 30ë¶„ë§ˆë‹¤ ìë™ìœ¼ë¡œ ê°€ê²©ì„ í™•ì¸í•˜ë©°,", "ê°€ê²©ì´ í•˜ë½í•˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.",
            "", "ğŸ”— ë„¤ì´ë²„ í•­ê³µê¶Œ:", link
        ])

        await status_message.edit_text(
            "\n".join(msg_lines),
            parse_mode="Markdown",
            disable_web_page_preview=True,
            reply_markup=final_keyboard
        )

    except NoFlightDataException as e:
        logger.warning(f"í•­ê³µê¶Œ ì¡°íšŒ ì‹¤íŒ¨ (ë°ì´í„° ì—†ìŒ, ì‚¬ìš©ì {user_id}): {e}")
        await status_message.edit_text(
            "â— ì§€ì›í•˜ì§€ ì•ŠëŠ” ê³µí•­ì´ê±°ë‚˜ í•´ë‹¹ ê²½ë¡œì˜ í•­ê³µí¸ì´ ì—†ìŠµë‹ˆë‹¤.\n"
            "ğŸ’¡ ì£¼ìš” ê³µí•­ ì½”ë“œ ëª©ë¡ì€ /airport ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            reply_markup=final_keyboard,
            parse_mode="Markdown"
        )
        return ConversationHandler.END
    except NoMatchingFlightsException as e:
        logger.warning(f"í•­ê³µê¶Œ ì¡°íšŒ ì‹¤íŒ¨ (ì¡°ê±´ ë¶ˆì¼ì¹˜, ì‚¬ìš©ì {user_id}): {e}")
        await status_message.edit_text(
             "â— í˜„ì¬ ì„¤ì •ëœ ì‹œê°„ ì¡°ê±´ì— ë§ëŠ” í•­ê³µê¶Œì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
             "ì‹œê°„ ì„¤ì •ì„ ë³€ê²½í•˜ì‹œë ¤ë©´ /settings ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.",
            reply_markup=final_keyboard,
            parse_mode="Markdown"
        )
        return ConversationHandler.END
    except Exception as e:
        logger.error(f"í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜ˆì¸¡í•˜ì§€ ëª»í•œ ì˜¤ë¥˜ (ì‚¬ìš©ì {user_id}): {e}", exc_info=True)
        await status_message.edit_text(
            "â— í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            reply_markup=final_keyboard,
            parse_mode="Markdown"
        )
        return ConversationHandler.END

async def monitor_job(context: ContextTypes.DEFAULT_TYPE):
    data = context.job.data
    user_id = data['chat_id']
    outbound_dep, outbound_arr, outbound_date, inbound_date = data['settings']
    hist_path = Path(data['hist_path'])

    if not hist_path.exists():
        logger.warning(f"monitor_job: íˆìŠ¤í† ë¦¬ íŒŒì¼ ì—†ìŒ, ì‘ì—… ì¤‘ë‹¨: {hist_path.name}")
        context.job.schedule_removal()
        return
        
    logger.info(f"monitor_job ì‹¤í–‰: {outbound_dep}->{outbound_arr}, íˆìŠ¤í† ë¦¬ íŒŒì¼: {hist_path.name}")

    try:
        state = await load_json_data_async(hist_path)
    except json.JSONDecodeError:
        logger.error(f"monitor_job: JSON ë””ì½”ë”© ì˜¤ë¥˜ {hist_path.name}. ì‘ì—… ì¤‘ë‹¨ ë° íŒŒì¼ ì‚­ì œ ì‹œë„.")
        try: hist_path.unlink()
        except OSError as e: logger.error(f"ì†ìƒëœ íˆìŠ¤í† ë¦¬ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {hist_path.name}: {e}")
        context.job.schedule_removal()
        return
    except FileNotFoundError:
        logger.warning(f"monitor_job: íˆìŠ¤í† ë¦¬ íŒŒì¼ (lock ë‚´ë¶€) ì—†ìŒ, ì‘ì—… ì¤‘ë‹¨: {hist_path.name}")
        context.job.schedule_removal()
        return

    old_restr = state.get("restricted", 0)
    old_overall = state.get("overall", 0)
    restricted, r_info, overall, o_info, link = None, "", None, "", ""

    try:
        restricted, r_info, overall, o_info, link = await fetch_prices(
            outbound_dep, outbound_arr, outbound_date, inbound_date, 3, user_id
        )
        
        _, dep_city, _ = get_airport_info(outbound_dep)
        _, arr_city, _ = get_airport_info(outbound_arr)
        dep_city = dep_city or outbound_dep
        arr_city = arr_city or outbound_arr

        notify_msg_lines = []
        price_change_occurred = False

        if restricted is not None and old_restr > 0 and restricted < old_restr:
            price_change_occurred = True
            notify_msg_lines.extend([
                f"ğŸ“‰ *{dep_city} â†” {arr_city} ê°€ê²© í•˜ë½ ì•Œë¦¼*", "",
                "ğŸ¯ *ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€*",
                f"ğŸ’° {old_restr:,}ì› â†’ *{restricted:,}ì›* (-{old_restr - restricted:,}ì›)",
                r_info
            ])

        if overall is not None and old_overall > 0 and overall < old_overall:
            if not price_change_occurred:
                 notify_msg_lines.extend([f"ğŸ“‰ *{dep_city} â†” {arr_city} ê°€ê²© í•˜ë½ ì•Œë¦¼*", ""])
            price_change_occurred = True
            notify_msg_lines.extend([
                "", "ğŸ“Œ *ì „ì²´ ìµœì €ê°€*",
                f"ğŸ’° {old_overall:,}ì› â†’ *{overall:,}ì›* (-{old_overall - overall:,}ì›)",
                o_info
            ])
            
        if price_change_occurred:
            notify_msg_lines.extend([
                "", f"ğŸ“… {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}",
                "ğŸ”— ë„¤ì´ë²„ í•­ê³µê¶Œ:", link
            ])
            try:
                await context.bot.send_message(
                    user_id, 
                    "\n".join(notify_msg_lines), 
                    parse_mode="Markdown",
                    disable_web_page_preview=True
                )
                logger.info(f"ê°€ê²© í•˜ë½ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ for {hist_path.name}")
            except Exception as send_error:
                logger.error(f"ê°€ê²© í•˜ë½ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ ({hist_path.name}): {send_error}")

    except NoMatchingFlightsException:
        logger.info(f"monitor_job: ì¡°ê±´ì— ë§ëŠ” í•­ê³µê¶Œ ì—†ìŒ - {hist_path.name}")
        user_config = await get_user_config_async(user_id)
        if old_restr != 0 or old_overall != 0:
            naver_link = f"https://flight.naver.com/flights/international/{outbound_dep}-{outbound_arr}-{outbound_date}/{outbound_arr}-{outbound_dep}-{inbound_date}?adult=1&fareType=Y"
            msg_lines = [
                f"â„¹ï¸ *{dep_city or outbound_dep} â†” {arr_city or outbound_arr} í•­ê³µê¶Œ ì•Œë¦¼*", "",
                "í˜„ì¬ ì„¤ì •í•˜ì‹  ì‹œê°„ ì¡°ê±´ì— ë§ëŠ” í•­ê³µê¶Œì´ ì—†ìŠµë‹ˆë‹¤.",
                f"â€¢ ê°€ëŠ” í¸ ì‹œê°„: {format_time_range(user_config, 'outbound')}",
                f"â€¢ ì˜¤ëŠ” í¸ ì‹œê°„: {format_time_range(user_config, 'inbound')}",
                "ì‹œê°„ ì„¤ì •ì„ ë³€ê²½í•˜ì‹œë ¤ë©´ /settings ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.", "",
                f"ğŸ“… {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}",
                f"ğŸ”— [ë„¤ì´ë²„ í•­ê³µê¶Œ ë°”ë¡œê°€ê¸°]({naver_link})"
            ]
            try:
                await context.bot.send_message(
                    user_id, 
                    "\n".join(msg_lines), 
                    parse_mode="Markdown",
                    disable_web_page_preview=True
                )
            except Exception as send_error:
                logger.error(f"í•­ê³µê¶Œ ì—†ìŒ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨ ({hist_path.name}): {send_error}")
    except NoFlightDataException:
        logger.warning(f"monitor_job: í•­ê³µê¶Œ ì •ë³´ ì—†ìŒ (ì•„ë§ˆë„ ê²½ë¡œ ë¬¸ì œ) - {hist_path.name}")
    except Exception as ex:
        logger.error(f"monitor_job ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({hist_path.name}): {ex}", exc_info=True)

    current_user_config = await get_user_config_async(user_id)
    new_state_data = {
        "start_time": state.get("start_time"),
        "restricted": restricted if restricted is not None else old_restr,
        "overall": overall if overall is not None else old_overall,
        "last_fetch": format_datetime(datetime.now()),
        "time_setting_outbound": format_time_range(current_user_config, 'outbound'),
        "time_setting_inbound": format_time_range(current_user_config, 'inbound')
    }
    logger.debug(f"[{hist_path.name}] ìƒíƒœ ì €ì¥ ì‹œë„: {new_state_data}")
    try:
        await save_json_data_async(hist_path, new_state_data)
        logger.info(f"[{hist_path.name}] ìƒíƒœ ì €ì¥ ë° last_fetch ì—…ë°ì´íŠ¸ ì„±ê³µ. ìƒˆ last_fetch: {new_state_data.get('last_fetch')}")
    except Exception as e_save:
        logger.error(f"CRITICAL: [{hist_path.name}] monitor_job ì‹¤í–‰ í›„ ìƒíƒœ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e_save}", exc_info=True)

@rate_limit
async def status(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ì‚¬ìš©ì {user_id} ìš”ì²­: /status")
    
    # ë¹„ë™ê¸°ì ìœ¼ë¡œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    loop = asyncio.get_running_loop()
    files = await loop.run_in_executor(
        file_executor,
        lambda: sorted([
            p for p in DATA_DIR.iterdir()
            if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id
        ])
    )
    
    if not files:
        await update.message.reply_text(
            "í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤."
        )
        return

    now = datetime.now(KST)
    msg_lines = ["ğŸ“‹ *ëª¨ë‹ˆí„°ë§ í˜„í™©*"]

    for idx, hist_file_path in enumerate(files, start=1):
        try:
            info = PATTERN.fullmatch(hist_file_path.name).groupdict()
            data = await load_json_data_async(hist_file_path)
            start_dt = datetime.strptime(
                data['start_time'], '%Y-%m-%d %H:%M:%S'
            ).replace(tzinfo=KST)
            elapsed = (now - start_dt).days
            
            dep, arr = info['dep'], info['arr']
            _, dep_city, _ = get_airport_info(dep)
            _, arr_city, _ = get_airport_info(arr)
            dep_city = dep_city or dep
            arr_city = arr_city or arr
            
            dd, rd = info['dd'], info['rd']
            dd_fmt = f"{dd[2:4]}.{dd[4:6]}.{dd[6:]}"
            rd_fmt = f"{rd[2:4]}.{rd[4:6]}.{rd[6:]}"
            
            prices = []
            if data['restricted']:
                prices.append(f"ì¡°ê±´ë¶€: {data['restricted']:,}ì›")
            if data['overall']:
                prices.append(f"ì „ì²´: {data['overall']:,}ì›")
            price_info = " / ".join(prices) if prices else "ì¡°íšŒëœ ê°€ê²© ì—†ìŒ"
            
            msg_lines.extend([
                "",
                f"*{idx}. {dep_city}({dep}) â†” {arr_city}({arr})*",
                f"ğŸ“… {dd_fmt} â†’ {rd_fmt}",
                f"ğŸ’° {price_info}",
                f"â±ï¸ {elapsed}ì¼ì§¸ ì§„í–‰ ì¤‘",
                f"ğŸ”„ ë§ˆì§€ë§‰ ì¡°íšŒ: {data['last_fetch']}",
                f"[ğŸ”— ë„¤ì´ë²„ í•­ê³µê¶Œ](https://flight.naver.com/flights/international/{dep}-{arr}-{dd}/{arr}-{dep}-{rd}?adult=1&fareType=Y)"
            ])
        except FileNotFoundError:
            logger.warning(f"Status: File not found for {hist_file_path.name}, skipping.")
            continue
        except json.JSONDecodeError:
            logger.warning(f"Status: JSON decode error for {hist_file_path.name}, skipping.")
            continue

    keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown",
        disable_web_page_preview=True,
        reply_markup=keyboard
    )

@rate_limit
async def cancel(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ì‚¬ìš©ì {user_id} ìš”ì²­: /cancel")
    
    # ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì°¾ê¸°
    files = sorted([
        p for p in DATA_DIR.iterdir()
        if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id
    ])
    
    if not files:
        keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()
        await update.message.reply_text(
            "í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.\n"
            "ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•˜ë ¤ë©´ /monitor ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”.",
            reply_markup=keyboard
        )
        return

    msg_lines = ["ğŸ“‹ *ì·¨ì†Œí•  ëª¨ë‹ˆí„°ë§ì„ ì„ íƒí•˜ì„¸ìš”*"]
    keyboard = []

    for idx, hist in enumerate(files, start=1):
        info = PATTERN.fullmatch(hist.name).groupdict()
        data = json.loads(hist.read_text(encoding='utf-8'))
        
        # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        dep, arr = info['dep'], info['arr']
        _, dep_city, _ = get_airport_info(dep)
        _, arr_city, _ = get_airport_info(arr)
        dep_city = dep_city or dep
        arr_city = arr_city or arr
        
        dd, rd = info['dd'], info['rd']
        
        # ëª¨ë‹ˆí„°ë§ ì •ë³´ í‘œì‹œ
        msg_lines.extend([
            "",
            f"*{idx}. {dep_city}({dep}) â†’ {arr_city}({arr})*",
            f"ğŸ“… {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}",
            "ğŸ’° ìµœì €ê°€ í˜„í™©:",
            f"  â€¢ ì¡°ê±´ë¶€: {data['restricted']:,}ì›" if data['restricted'] else "  â€¢ ì¡°ê±´ë¶€: ì—†ìŒ",
            f"  â€¢ ì „ì²´: {data['overall']:,}ì›" if data['overall'] else "  â€¢ ì „ì²´: ì—†ìŒ"
        ])
        
        # ì¸ë¼ì¸ ë²„íŠ¼ ì¶”ê°€
        keyboard.append([
            InlineKeyboardButton(
                f"âŒ {idx}ë²ˆ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ",
                callback_data=f"cancel_{hist.name}"
            )
        ])

    # ì „ì²´ ì·¨ì†Œ ë²„íŠ¼ ì¶”ê°€
    keyboard.append([
        InlineKeyboardButton(
            "ğŸ—‘ï¸ ì „ì²´ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ",
            callback_data="cancel_all"
        )
    ])

    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )

async def cancel_callback(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    data = query.data
    logger.info(f"ì‚¬ìš©ì {user_id} ì½œë°±: {data}")
    
    monitors = ctx.application.bot_data.get("monitors", {})
    user_mons = monitors.get(user_id, [])
    keyboard = get_admin_keyboard() if user_id in ADMIN_IDS else get_base_keyboard()

    if data == "cancel_all":
        files = [
            p for p in DATA_DIR.iterdir()
            if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id
        ]
        if not files:
            await query.answer("ì·¨ì†Œí•  ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        msg_lines = ["âœ… ëª¨ë“  ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤:"]
        for hist in files:
            m = PATTERN.fullmatch(hist.name)
            dep, arr = m.group("dep"), m.group("arr")
            dd, rd = m.group("dd"), m.group("rd")
            # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            _, dep_city, _ = get_airport_info(dep)
            _, arr_city, _ = get_airport_info(arr)
            dep_city = dep_city or dep
            arr_city = arr_city or arr
            msg_lines.append(
                f"â€¢ {dep_city}({dep}) â†’ {arr_city}({arr})\n"
                f"  {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}"
            )
            hist.unlink()
            for job in ctx.application.job_queue.get_jobs_by_name(str(hist)):
                job.schedule_removal()
        
        monitors.pop(user_id, None)
        await query.message.edit_text(
            "\n".join(msg_lines),
            parse_mode="Markdown"
        )
        await query.answer("ëª¨ë“  ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return

    if data.startswith("cancel_"):
        target_file = data[7:]  # "cancel_" ì œê±°
        target = DATA_DIR / target_file
        
        if not target.exists():
            await query.answer("ì´ë¯¸ ì·¨ì†Œëœ ëª¨ë‹ˆí„°ë§ì…ë‹ˆë‹¤.")
            return
            
        m = PATTERN.fullmatch(target_file)
        dep, arr = m.group("dep"), m.group("arr")
        dd, rd = m.group("dd"), m.group("rd")
        
        # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        _, dep_city, _ = get_airport_info(dep)
        _, arr_city, _ = get_airport_info(arr)
        dep_city = dep_city or dep
        arr_city = arr_city or arr
        
        target.unlink()
        for job in ctx.application.job_queue.get_jobs_by_name(str(target)):
            job.schedule_removal()

        if user_id in monitors:
            monitors[user_id] = [m for m in user_mons if m.get('hist_path') != str(target)]
            if not monitors[user_id]:
                monitors.pop(user_id)
                
        msg_lines = [
            "âœ… ë‹¤ìŒ ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤:",
            f"â€¢ {dep_city}({dep}) â†’ {arr_city}({arr})",
            f"  {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}"
        ]
        
        await query.message.edit_text(
            "\n".join(msg_lines),
            parse_mode="Markdown"
        )
        await query.answer("ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")

async def all_status(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ê´€ë¦¬ì {user_id} ìš”ì²­: /allstatus")
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ëª¨ë“  ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì°¾ê¸°
    files = sorted(DATA_DIR.glob("price_*.json"))
    if not files:
        await update.message.reply_text("í˜„ì¬ ë“±ë¡ëœ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ ì§‘ê³„
    user_counts = defaultdict(int)
    for hist_path in files:
        try:
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                continue
            uid = int(m.group("uid"))
            user_counts[uid] += 1
        except Exception as e:
            logger.error(f"ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
    total_users = len(user_counts)
    total_monitors = len(files)
    msg_lines = [
        f"ğŸ“Š *ì „ì²´ ëª¨ë‹ˆí„°ë§ í˜„í™©*",
        f"â€¢ ì´ ì‚¬ìš©ì ìˆ˜: {total_users}ëª…",
        f"â€¢ ì´ ëª¨ë‹ˆí„°ë§ ìˆ˜: {total_monitors}ê±´",
        "",
        "ğŸ“‹ *ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ í˜„í™©*"
    ]

    # ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ ì •ë ¬ (ê°œìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
    sorted_users = sorted(user_counts.items(), key=lambda x: (-x[1], x[0]))
    for uid, count in sorted_users:
        msg_lines.append(f"â€¢ ì‚¬ìš©ì {uid}: {count}ê±´")

    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown"
    )

async def all_cancel(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ê´€ë¦¬ì {user_id} ìš”ì²­: /allcancel")
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ëª¨ë“  ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì°¾ê¸°
    files = list(DATA_DIR.glob("price_*.json"))
    if not files:
        await update.message.reply_text("í˜„ì¬ ë“±ë¡ëœ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í™•ì¸ ë²„íŠ¼ì´ ìˆëŠ” ì¸ë¼ì¸ í‚¤ë³´ë“œ ìƒì„±
    keyboard = [
        [
            InlineKeyboardButton("âœ… ì˜ˆ, ëª¨ë‘ ì·¨ì†Œí•©ë‹ˆë‹¤", callback_data="confirm_allcancel"),
            InlineKeyboardButton("âŒ ì•„ë‹ˆì˜¤", callback_data="cancel_allcancel")
        ]
    ]

    await update.message.reply_text(
        f"âš ï¸ *ì£¼ì˜*: ì •ë§ ëª¨ë“  ëª¨ë‹ˆí„°ë§({len(files)}ê±´)ì„ ì·¨ì†Œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
        parse_mode="Markdown",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )

async def all_cancel_callback(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    user_id = query.from_user.id
    
    if user_id not in ADMIN_IDS:
        await query.answer("âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
        
    if query.data == "cancel_allcancel":
        # ì¸ë¼ì¸ í‚¤ë³´ë“œ ì œê±°
        await query.message.edit_text(
            "ëª¨ë‹ˆí„°ë§ ì·¨ì†Œê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
        )
        # ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê´€ë¦¬ì í‚¤ë³´ë“œ í‘œì‹œ
        keyboard = get_admin_keyboard()
        await query.message.reply_text(
            "ë‹¤ë¥¸ ì‘ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
            reply_markup=keyboard
        )
        await query.answer("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return
        
    if query.data != "confirm_allcancel":
        return

    files = list(DATA_DIR.glob("price_*.json"))
    count = 0
    error_count = 0
    processed_users = set()

    for hist_path in files:
        try:
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                continue

            uid = int(m.group("uid"))
            processed_users.add(uid)

            try:
                hist_path.unlink()
                count += 1
            except FileNotFoundError:
                pass
            except Exception as e:
                error_count += 1
                logger.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({hist_path.name}): {e}")

            for job in ctx.application.job_queue.get_jobs_by_name(str(hist_path)):
                job.schedule_removal()

        except Exception as e:
            error_count += 1
            logger.error(f"ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    monitors = ctx.application.bot_data.get("monitors", {})
    for uid in processed_users:
        monitors.pop(uid, None)

    msg_parts = [f"âœ… ì „ì²´ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ: {count}ê±´ ì²˜ë¦¬ë¨"]
    if error_count > 0:
        msg_parts.append(f"âš ï¸ {error_count}ê±´ì˜ ì˜¤ë¥˜ ë°œìƒ")
    
    # ì¸ë¼ì¸ í‚¤ë³´ë“œ ì œê±°
    await query.message.edit_text(
        "\n".join(msg_parts)
    )
    # ìƒˆë¡œìš´ ë©”ì‹œì§€ë¡œ ê´€ë¦¬ì í‚¤ë³´ë“œ í‘œì‹œ
    keyboard = get_admin_keyboard()
    await query.message.reply_text(
        "ë‹¤ë¥¸ ì‘ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.",
        reply_markup=keyboard
    )
    await query.answer("ëª¨ë“  ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    logger.info(f"ì „ì²´ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ: {count}ê±´ ì²˜ë¦¬ë¨, {error_count}ê±´ì˜ ì˜¤ë¥˜")

async def on_startup(app: ApplicationBuilder): # Type hint for app
    now = datetime.now(KST)
    monitors = app.bot_data.setdefault("monitors", {})
    logger.info("ë´‡ ì‹œì‘ ì‹œ on_startup ì‹¤í–‰: ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ ë³µì› ì‹œì‘")

    processed_files = 0
    active_jobs_restored = 0

    for hist_path in DATA_DIR.glob("price_*.json"):
        processed_files += 1
        try:
            logger.debug(f"ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {hist_path.name}")
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                logger.warning(f"ì˜ëª»ëœ ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì´ë¦„ íŒ¨í„´: {hist_path.name}")
                continue

            try:
                data = await load_json_data_async(hist_path) # Consistent locking
            except json.JSONDecodeError:
                logger.error(f"ëª¨ë‹ˆí„°ë§ ë³µì› ì¤‘ JSON ë””ì½”ë”© ì˜¤ë¥˜ ({hist_path.name}). íŒŒì¼ ì‚­ì œ ì‹œë„.")
                try: hist_path.unlink()
                except OSError as e_unlink: logger.error(f"ì†ìƒëœ ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({hist_path.name}): {e_unlink}")
                continue
            except FileNotFoundError: # Should not happen if glob caught it, but for safety
                logger.warning(f"ëª¨ë‹ˆí„°ë§ ë³µì› ì¤‘ íŒŒì¼ ì—†ìŒ (race condition?): {hist_path.name}")
                continue

            start_time_str = data.get("start_time") # For monitor metadata

            last_fetch_str = data.get("last_fetch")
            last_fetch_source_for_log = last_fetch_str # For logging original value
            
            if not last_fetch_str:
                logger.warning(f"last_fetch ëˆ„ë½ ({hist_path.name}). ì¦‰ì‹œ ì‹¤í–‰ ë° ì •ê¸° ê°„ê²©ìœ¼ë¡œ ì˜ˆì•½ë©ë‹ˆë‹¤.")
                last_fetch = now - timedelta(minutes=31) # 30ë¶„ ì´ìƒ ê²½ê³¼í•œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                last_fetch_source_for_log = f"ëˆ„ë½ë˜ì–´ '{format_datetime(last_fetch)}'ë¡œ ì„¤ì •ë¨"
            else:
                try:
                    last_fetch = datetime.strptime(last_fetch_str, "%Y-%m-%d %H:%M:%S").replace(tzinfo=KST)
                except ValueError as e_time:
                    logger.warning(f"ì˜ëª»ëœ last_fetch í˜•ì‹ ({hist_path.name}): '{last_fetch_str}' ({e_time}). ì¦‰ì‹œ ì‹¤í–‰ ë° ì •ê¸° ê°„ê²©ìœ¼ë¡œ ì˜ˆì•½ë©ë‹ˆë‹¤.")
                    last_fetch = now - timedelta(minutes=31) # 30ë¶„ ì´ìƒ ê²½ê³¼í•œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                    last_fetch_source_for_log = f"í˜•ì‹ì˜¤ë¥˜ë¡œ '{format_datetime(last_fetch)}'ë¡œ ì„¤ì •ë¨"


            interval = timedelta(minutes=30)
            delta = now - last_fetch

            uid = int(m.group("uid"))
            dep, arr, dd, rd = m.group("dep"), m.group("arr"), m.group("dd"), m.group("rd")
            
            job_base_name = str(hist_path) # Base name for jobs related to this monitor

            # ì¦‰ì‹œ ì‹¤í–‰ ì‘ì—… (Catch-up job)
            if delta >= interval:
                logger.info(
                    f"ì¦‰ì‹œ ì¡°íšŒ ì˜ˆì•½ (Overdue): {hist_path.name} | "
                    f"Last Fetch: {last_fetch_source_for_log} | Now: {format_datetime(now)} | Delta: {delta.total_seconds()/60:.1f}ë¶„ | "
                    f"ì˜ˆì•½: ì¦‰ì‹œ ì‹¤í–‰"
                )
                app.job_queue.run_once(
                    monitor_job,
                    when=timedelta(seconds=0), # Run ASAP
                    name=f"{job_base_name}_startup_immediate", # Unique name for the immediate job
                    data={
                        "chat_id": uid,
                        "settings": (dep, arr, dd, rd),
                        "hist_path": str(hist_path) # Ensure it's a string
                    }
                )

            # ì •ê¸° ë°˜ë³µ ì‘ì—… (Repeating job)
            if delta.total_seconds() < 0: # last_fetch is in the future (e.g. system clock changed)
                next_run_delay = interval # Schedule it one interval from now
                logger.warning(
                    f"last_fetchê°€ ë¯¸ë˜ ì‹œê°„ì…ë‹ˆë‹¤ ({hist_path.name}): {format_datetime(last_fetch)}. "
                    f"ë‹¤ìŒ ì •ê¸° ì‹¤í–‰ì€ {next_run_delay.total_seconds()/60:.1f}ë¶„ í›„ë¡œ ì˜ˆì•½í•©ë‹ˆë‹¤."
                )
            else:
                time_into_current_cycle = delta % interval
                next_run_delay = interval - time_into_current_cycle
                # If next_run_delay is zero, it means it's exactly on the interval boundary.
                # The job should run 'interval' seconds later because the current "due" slot
                # is either handled by the immediate job (if overdue) or it's not yet time.
                if next_run_delay.total_seconds() == 0 and delta.total_seconds() > 0 : # Exactly on time (and not delta=0)
                     next_run_delay = interval


            logger.info(
                f"ì •ê¸° ëª¨ë‹ˆí„°ë§ ë“±ë¡: {hist_path.name} | "
                f"Last Fetch: {last_fetch_source_for_log} | Now: {format_datetime(now)} | Delta: {delta.total_seconds()/60:.1f}ë¶„ | "
                f"ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ì•½: {next_run_delay.total_seconds()/60:.1f}ë¶„"
            )

            job = app.job_queue.run_repeating(
                monitor_job,
                interval=interval,
                first=next_run_delay, # timedelta specifying the delay for the first run
                name=job_base_name,    # Use the base name for the repeating job
                data={
                    "chat_id": uid,
                    "settings": (dep, arr, dd, rd),
                    "hist_path": str(hist_path) # Ensure it's a string
                }
            )
            active_jobs_restored +=1

            # ëª¨ë‹ˆí„°ë§ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ì„ íƒ ì‚¬í•­)
            parsed_start_time = now # Fallback
            if start_time_str:
                try:
                    parsed_start_time = datetime.strptime(start_time_str, "%Y-%m-%d %H:%M:%S").replace(tzinfo=KST)
                except ValueError:
                    logger.warning(f"ì˜ëª»ëœ start_time í˜•ì‹ ({hist_path.name}): '{start_time_str}'")
            
            monitors.setdefault(uid, []).append({
                "settings": (dep, arr, dd, rd),
                "start_time": parsed_start_time,
                "hist_path": str(hist_path),
                "job_name_repeating": job.name 
            })

        except Exception as ex_outer: # Catch any unexpected error during single file processing
            logger.error(f"ëª¨ë‹ˆí„°ë§ ë³µì› ì¤‘ ({hist_path.name}) ì²˜ë¦¬ ì‹¤íŒ¨: {ex_outer}", exc_info=True)
            # Consider removing the problematic hist_path file if errors persist across restarts
            # try:
            #     hist_path.unlink(missing_ok=True)
            #     logger.info(f"ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì‚­ì œ ì‹œë„: {hist_path.name}")
            # except OSError as e_unlink_outer:
            #     logger.error(f"ì˜¤ë¥˜ ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({hist_path.name}): {e_unlink_outer}")

    logger.info(f"ëª¨ë‹ˆí„°ë§ ë³µì› ì™„ë£Œ: ì´ {processed_files}ê°œ íŒŒì¼ ì²˜ë¦¬, {active_jobs_restored}ê°œ ì‘ì—… í™œì„±/ì¬ê°œë¨.")

@contextlib.contextmanager
def file_lock(file_path):
    """íŒŒì¼ ì ê¸ˆì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    lock_path = str(file_path) + '.lock'
    with open(lock_path, 'w') as lock_file:
        try:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
            yield
        finally:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            if os.path.exists(lock_path):
                os.unlink(lock_path)

def save_json_data(file_path: Path, data: dict):
    """ìŠ¤ë ˆë“œ ì„¸ì´í”„í•œ JSON ë°ì´í„° ì €ì¥"""
    with file_lock(file_path):
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

def load_json_data(file_path: Path) -> dict:
    """ìŠ¤ë ˆë“œ ì„¸ì´í”„í•œ JSON ë°ì´í„° ë¡œë“œ"""
    with file_lock(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

# Modified cleanup_old_data function signature and body
async def cleanup_old_data(context: ContextTypes.DEFAULT_TYPE): # Add context argument
    """ì˜¤ë˜ëœ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ì™€ ì„¤ì • íŒŒì¼ ì •ë¦¬"""
    retention_days = int(os.getenv("DATA_RETENTION_DAYS", "30"))
    config_retention_days = int(os.getenv("CONFIG_RETENTION_DAYS", "7"))
    cutoff_date = datetime.now(KST) - timedelta(days=retention_days)
    config_cutoff_date = datetime.now(KST) - timedelta(days=config_retention_days)

    monitor_deleted = 0
    config_deleted = 0

    # ì˜¤ë˜ëœ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì •ë¦¬
    for file_path in DATA_DIR.glob("price_*.json"):
        try:
            # Use load_json_data for consistent locking
            data = await load_json_data_async(file_path)
            start_time_str = data.get("start_time")
            if not start_time_str:
                logger.warning(f"ë°ì´í„° ì •ë¦¬ ì¤‘ 'start_time' ëˆ„ë½: {file_path.name}, íŒŒì¼ ì‚­ì œ ì‹œë„.")
                try:
                    file_path.unlink()
                    monitor_deleted +=1
                except OSError as e:
                    logger.error(f"ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{file_path.name}': {e}")
                continue

            start_time = datetime.strptime(
                start_time_str,
                "%Y-%m-%d %H:%M:%S"
            ).replace(tzinfo=KST)
            if start_time < cutoff_date:
                logger.info(f"ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ: {file_path.name}")
                try:
                    file_path.unlink()
                    monitor_deleted += 1
                except OSError as e:
                    logger.error(f"ì˜¤ë˜ëœ ë°ì´í„° íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{file_path.name}': {e}")
        except json.JSONDecodeError:
            logger.warning(f"ë°ì´í„° ì •ë¦¬ ì¤‘ JSON ë””ì½”ë”© ì˜¤ë¥˜: {file_path.name}, íŒŒì¼ ì‚­ì œ ì‹œë„.")
            try:
                file_path.unlink() # Delete corrupted file
                monitor_deleted +=1
            except OSError as e:
                logger.error(f"ì†ìƒëœ ë°ì´í„° íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{file_path.name}': {e}")
        except Exception as ex:
            logger.warning(f"ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({file_path.name}): {ex}")

    # ì˜¤ë˜ëœ ì„¤ì • íŒŒì¼ ì •ë¦¬
    for config_file in USER_CONFIG_DIR.glob("config_*.json"):
        try:
            # file_lock is already part of load_json_data, but user config has custom load/save
            with file_lock(config_file):
                if not config_file.exists(): continue # Might have been deleted by another process/thread
                
                data = json.loads(config_file.read_text(encoding='utf-8'))
                last_activity_str = data.get('last_activity', data.get('created_at'))

                if not last_activity_str:
                    logger.warning(f"ì„¤ì • íŒŒì¼ ì •ë¦¬ ì¤‘ 'last_activity' ë˜ëŠ” 'created_at' ëˆ„ë½: {config_file.name}, íŒŒì¼ ì‚­ì œ ì‹œë„.")
                    try:
                        config_file.unlink()
                        config_deleted += 1
                    except OSError as e:
                        logger.error(f"ì˜¤ë˜ëœ ì„¤ì • íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{config_file.name}': {e}")
                    continue
                
                last_activity = datetime.strptime(
                    last_activity_str,
                    '%Y-%m-%d %H:%M:%S'
                ).replace(tzinfo=KST)

                if last_activity < config_cutoff_date:
                    user_id_match = re.search(r"config_(\d+)\.json", config_file.name)
                    if not user_id_match:
                        logger.warning(f"ì„¤ì • íŒŒì¼ ì´ë¦„ì—ì„œ user_id ì¶”ì¶œ ë¶ˆê°€: {config_file.name}")
                        continue
                    user_id = int(user_id_match.group(1))

                    active_monitors = [
                        p for p in DATA_DIR.glob(f"price_{user_id}_*.json")
                        if p.exists() # Check if monitor file actually exists
                    ]
                    if not active_monitors:
                        logger.info(f"ë¹„í™œì„± ì‚¬ìš©ì ì„¤ì • ì‚­ì œ: {config_file.name}")
                        try:
                            config_file.unlink()
                            config_deleted += 1
                        except OSError as e:
                            logger.error(f"ë¹„í™œì„± ì‚¬ìš©ì ì„¤ì • íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{config_file.name}': {e}")
        except json.JSONDecodeError:
            logger.warning(f"ì„¤ì • íŒŒì¼ ì •ë¦¬ ì¤‘ JSON ë””ì½”ë”© ì˜¤ë¥˜: {config_file.name}, íŒŒì¼ ì‚­ì œ ì‹œë„.")
            try:
                with file_lock(config_file): # ensure lock for deletion if it still exists
                    if config_file.exists():
                         config_file.unlink()
                         config_deleted +=1
            except OSError as e:
                logger.error(f"ì†ìƒëœ ì„¤ì • íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ '{config_file.name}': {e}")
        except Exception as ex:
            logger.warning(f"ì„¤ì • íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({config_file.name}): {ex}")

    if ADMIN_IDS and (monitor_deleted > 0 or config_deleted > 0) : # Only notify if changes were made
        msg = (
            "ğŸ§¹ *ë°ì´í„° ì •ë¦¬ ì™„ë£Œ*\n"
            f"â€¢ ì‚­ì œëœ ëª¨ë‹ˆí„°ë§: {monitor_deleted}ê±´\n"
            f"â€¢ ì‚­ì œëœ ì„¤ì • íŒŒì¼: {config_deleted}ê±´\n\n"
            f"ëª¨ë‹ˆí„°ë§ ë³´ê´€ ê¸°ê°„: {retention_days}ì¼\n"
            f"ì„¤ì • íŒŒì¼ ë³´ê´€ ê¸°ê°„: {config_retention_days}ì¼"
        )
        for admin_id in ADMIN_IDS:
            try:
                await context.bot.send_message( # Use context.bot
                    chat_id=admin_id,
                    text=msg,
                    parse_mode="Markdown"
                )
            except Exception as ex:
                logger.error(f"ê´€ë¦¬ì({admin_id})ì—ê²Œ ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {ex}")

async def airport_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ê³µí•­ ì½”ë“œ ëª©ë¡ ë³´ê¸°"""
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /airport")
    # airport ëª…ë ¹ì–´ ì‹¤í–‰ ì‹œ í‚¤ë³´ë“œ ìœ ì§€
    keyboard = get_admin_keyboard() if update.effective_user.id in ADMIN_IDS else get_base_keyboard()
    await update.message.reply_text(
        format_airport_list(),
        parse_mode="Markdown",
        reply_markup=keyboard
    )

async def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
    logger.info("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
    selenium_manager.shutdown()
    file_executor.shutdown(wait=True)
    logger.info("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")

def main():
    logger.info("ë©”ì¸ í•¨ìˆ˜ ì‹œì‘: ApplicationBuilder ì„¤ì • ì¤‘...")
    
    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    errors = validate_env_vars()
    if errors:
        for error in errors:
            logger.error(error)
        return
    
    if not BOT_TOKEN:
        logger.error("í™˜ê²½ë³€ìˆ˜ BOT_TOKENì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    application = ApplicationBuilder().token(BOT_TOKEN).build()
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    # í•¸ë“¤ëŸ¬ ë“±ë¡
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("monitor", monitor_cmd)],
        states={
            SETTING: [
                MessageHandler(filters.TEXT & ~filters.COMMAND, monitor_setting),
                CommandHandler("cancel", cancel_conversation)
            ]
        },
        fallbacks=[CommandHandler("cancel", cancel_conversation)],
    )
    
    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_cmd))
    application.add_handler(CommandHandler("status", status))
    application.add_handler(CommandHandler("cancel", cancel))
    application.add_handler(CommandHandler("airport", airport_cmd))
    application.add_handler(CommandHandler("settings", settings_cmd))
    application.add_handler(CommandHandler("set", set_cmd))
    
    # ì½œë°± ì¿¼ë¦¬ í•¸ë“¤ëŸ¬ ì¶”ê°€ (íŒ¨í„´ì´ ë” êµ¬ì²´ì ì¸ ê²ƒì„ ë¨¼ì € ë“±ë¡)
    application.add_handler(CallbackQueryHandler(all_cancel_callback, pattern="^(confirm|cancel)_allcancel$"))
    application.add_handler(CallbackQueryHandler(cancel_callback, pattern="^cancel_"))
    
    # ê´€ë¦¬ì ëª…ë ¹ì–´
    if ADMIN_IDS:
        application.add_handler(CommandHandler("allstatus", all_status))
        application.add_handler(CommandHandler("allcancel", all_cancel))
    
    # ë§¤ì¼ ìì •ì— ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
    application.job_queue.run_daily(
        cleanup_old_data,
        time=time(hour=0, minute=0, tzinfo=KST)
    )
    
    logger.info("ë´‡ ì‹¤í–‰ ì‹œì‘")
    # ì‹œì‘ ì‹œ on_startup í•¨ìˆ˜ ì§ì ‘ ì‹¤í–‰
    asyncio.get_event_loop().run_until_complete(on_startup(application))
    
    try:
        # ë´‡ ì‹¤í–‰
        application.run_polling()
    finally:
        # ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        asyncio.get_event_loop().run_until_complete(cleanup_resources())

if __name__ == "__main__":
    main()
