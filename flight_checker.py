#!/usr/bin/env python3
"""
í…”ë ˆê·¸ë¨ ë´‡ìœ¼ë¡œ 30ë¶„ë§ˆë‹¤ í•­ê³µê¶Œ ìµœì €ê°€ ì¡°íšŒ ë° ì•Œë¦¼ ê¸°ëŠ¥ ì œê³µ
í™˜ê²½ë³€ìˆ˜ ì„¤ì • (í•„ìˆ˜):
- BOT_TOKEN         : Telegram ë´‡ í† í°
- SELENIUM_HUB_URL  : Selenium Hub ì£¼ì†Œ (ê¸°ë³¸: http://localhost:4444/wd/hub)
- ADMIN_IDS         : ê´€ë¦¬ì ID ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„)
- USER_AGENT        : (ì„ íƒ) Selenium í—¤ë“œë¦¬ìŠ¤ ë¸Œë¼ìš°ì €ìš© User-Agent
- MAX_MONITORS      : (ì„ íƒ) ì‚¬ìš©ìë‹¹ ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ (ê¸°ë³¸ 3)
- DATA_RETENTION_DAYS: (ì„ íƒ) ë°ì´í„° ë³´ê´€ ê¸°ê°„ (ì¼, ê¸°ë³¸ 30)
"""
import os
import re
import json
import time as time_module
import logging
import asyncio
import fcntl
import contextlib
from pathlib import Path
from datetime import datetime, timedelta, time
from zoneinfo import ZoneInfo
from collections import defaultdict
from telegram import Update
from telegram.ext import (
    ApplicationBuilder, CommandHandler,
    MessageHandler, ConversationHandler,
    ContextTypes, filters, JobQueue
)
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# --- ì„¤ì • ë° ì´ˆê¸°í™” ---
DATA_DIR = Path("/data")
DATA_DIR.mkdir(parents=True, exist_ok=True)

LOG_DIR = DATA_DIR / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = LOG_DIR / "flight_bot.log"

# ì‚¬ìš©ì ì„¤ì • ë””ë ‰í† ë¦¬
USER_CONFIG_DIR = DATA_DIR / "user_configs"
USER_CONFIG_DIR.mkdir(parents=True, exist_ok=True)

# ì‹œê°„ëŒ€ ì„¤ì •
TIME_PERIODS = {
    "ìƒˆë²½": (0, 6),    # 00:00 ~ 06:00
    "ì˜¤ì „1": (6, 9),   # 06:00 ~ 09:00
    "ì˜¤ì „2": (9, 12),  # 09:00 ~ 12:00
    "ì˜¤í›„1": (12, 15), # 12:00 ~ 15:00
    "ì˜¤í›„2": (15, 18), # 15:00 ~ 18:00
    "ë°¤1": (18, 21),   # 18:00 ~ 21:00
    "ë°¤2": (21, 24),   # 21:00 ~ 00:00
}

# ê¸°ë³¸ ì„¤ì •ê°’
DEFAULT_USER_CONFIG = {
    "time_type": "time_period",        # 'time_period' ë˜ëŠ” 'exact'
    "outbound_periods": ["ì˜¤ì „1", "ì˜¤ì „2"],  # ê°€ëŠ” í¸ ì‹œê°„ëŒ€
    "inbound_periods": ["ì˜¤í›„1", "ì˜¤í›„2", "ë°¤1"],  # ì˜¤ëŠ” í¸ ì‹œê°„ëŒ€
    "outbound_exact_hour": 9,          # ê°€ëŠ” í¸ ì‹œê° (ì‹œê°„ ë‹¨ìœ„)
    "inbound_exact_hour": 15,          # ì˜¤ëŠ” í¸ ì‹œê° (ì‹œê°„ ë‹¨ìœ„)
    "last_activity": None,             # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„
    "created_at": None                 # ì„¤ì • ìƒì„± ì‹œê°„
}

def get_user_config(user_id: int) -> dict:
    """ì‚¬ìš©ì ì„¤ì •ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    config_file = USER_CONFIG_DIR / f"config_{user_id}.json"
    if config_file.exists():
        try:
            with file_lock(config_file):
                data = json.loads(config_file.read_text(encoding='utf-8'))
                # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
                data['last_activity'] = format_datetime(datetime.now())
                config_file.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding='utf-8')
                return data
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì„¤ì • ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ì„¤ì • íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±
    default_config = DEFAULT_USER_CONFIG.copy()
    default_config['created_at'] = format_datetime(datetime.now())
    default_config['last_activity'] = format_datetime(datetime.now())
    save_user_config(user_id, default_config)
    return default_config

def save_user_config(user_id: int, config: dict):
    """ì‚¬ìš©ì ì„¤ì •ì„ ì €ì¥í•©ë‹ˆë‹¤."""
    config_file = USER_CONFIG_DIR / f"config_{user_id}.json"
    with file_lock(config_file):
        config_file.write_text(json.dumps(config, ensure_ascii=False, indent=2), encoding='utf-8')

def get_time_range(config: dict, direction: str) -> tuple[time, time]:
    """ì‹œê°„ ë²”ìœ„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Args:
        config: ì‚¬ìš©ì ì„¤ì •
        direction: 'outbound' ë˜ëŠ” 'inbound'
        
    Returns:
        tuple[time, time]: ì‹œì‘ ì‹œê°ê³¼ ì¢…ë£Œ ì‹œê°
    """
    if config['time_type'] == 'time_period':
        periods = config[f'{direction}_periods']
        period_ranges = [TIME_PERIODS[p] for p in periods]
        start_hours = [start for start, _ in period_ranges]
        end_hours = [end for _, end in period_ranges]
        
        if direction == 'outbound':
            # ê°€ëŠ” í¸: ì„ íƒí•œ ì‹œê°„ëŒ€ì— í¬í•¨ë˜ëŠ” í•­ê³µí¸ë§Œ
            return time(hour=min(start_hours), minute=0), time(hour=max(end_hours), minute=0)
        else:
            # ì˜¤ëŠ” í¸: ì„ íƒí•œ ì‹œê°„ëŒ€ì— í¬í•¨ë˜ëŠ” í•­ê³µí¸ë§Œ
            # ì‹œê°„ëŒ€ê°€ ì—°ì†ë˜ì§€ ì•Šì„ ê²½ìš°ë¥¼ ìœ„í•´ ì „ì²´ ë²”ìœ„ë¡œ ì„¤ì •
            # ì˜ˆ: ì˜¤ì „1(06-09)ê³¼ ì˜¤í›„2(15-18)ë¥¼ ì„ íƒí•œ ê²½ìš°
            # 06:00-18:00 ì‚¬ì´ì˜ ëª¨ë“  í•­ê³µí¸ì„ í¬í•¨
            return time(hour=min(start_hours), minute=0), time(hour=max(end_hours), minute=0)
    else:  # exact
        hour = config[f'{direction}_exact_hour']
        if direction == 'outbound':
            # ê°€ëŠ” í¸ì€ "ì´ì „"ì´ë¯€ë¡œ ì •í™•í•œ ì‹œê°ì´ ë ì‹œê°
            return time(hour=0, minute=0), time(hour=hour, minute=0)
        else:
            # ì˜¤ëŠ” í¸ì€ "ì´í›„"ì´ë¯€ë¡œ ì •í™•í•œ ì‹œê°ì´ ì‹œì‘ ì‹œê°
            return time(hour=hour, minute=0), time(hour=24, minute=0)

def format_time_range(config: dict, direction: str) -> str:
    """ì‹œê°„ ì„¤ì •ì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if config['time_type'] == 'time_period':
        periods = config[f'{direction}_periods']
        period_ranges = [TIME_PERIODS[p] for p in periods]
        start_hours = [start for start, _ in period_ranges]
        end_hours = [end for _, end in period_ranges]
        period_str = ", ".join(periods)
        
        if direction == 'outbound':
            return f"{period_str} ({min(start_hours):02d}:00-{max(end_hours):02d}:00)"
        else:
            # ì˜¤ëŠ” í¸ì€ ì„ íƒí•œ ì‹œê°„ëŒ€ë“¤ì„ ëª¨ë‘ í‘œì‹œ
            time_ranges = [f"{start:02d}:00-{end:02d}:00" for start, end in period_ranges]
            return f"{period_str} ({' / '.join(time_ranges)})"
    else:  # exact
        hour = config[f'{direction}_exact_hour']
        return f"{hour:02d}:00 {'ì´ì „' if direction == 'outbound' else 'ì´í›„'}"

async def settings_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ì‚¬ìš©ì ì„¤ì • í™•ì¸ ë° ë³€ê²½"""
    user_id = update.effective_user.id
    config = get_user_config(user_id)
    
    msg_lines = [
        "âš™ï¸ *ì‹œê°„ ì œí•œ ì„¤ì •*",
        "",
        "*í˜„ì¬ ì„¤ì •*",
        f"â€¢ ê°€ëŠ” í¸: {format_time_range(config, 'outbound')}",
        f"â€¢ ì˜¤ëŠ” í¸: {format_time_range(config, 'inbound')}",
        "",
        "*ì„¤ì • ë°©ë²•*",
        "1ï¸âƒ£ *ì‹œê°„ëŒ€ë¡œ ì„¤ì •* (í•´ë‹¹ ì‹œê°„ëŒ€ì˜ í•­ê³µí¸ë§Œ ê²€ìƒ‰)",
        "â€¢ ê°€ëŠ” í¸: `/set ê°€ëŠ”í¸ ì‹œê°„ëŒ€ ì˜¤ì „1 ì˜¤ì „2`",
        "â€¢ ì˜¤ëŠ” í¸: `/set ì˜¤ëŠ”í¸ ì‹œê°„ëŒ€ ì˜¤í›„1 ì˜¤í›„2 ë°¤1`",
        "",
        "2ï¸âƒ£ *íŠ¹ì • ì‹œê°ìœ¼ë¡œ ì„¤ì •*",
        "â€¢ ê°€ëŠ” í¸: `/set ê°€ëŠ”í¸ ì‹œê° 9` (09:00 ì´ì „ ì¶œë°œ)",
        "â€¢ ì˜¤ëŠ” í¸: `/set ì˜¤ëŠ”í¸ ì‹œê° 15` (15:00 ì´í›„ ì¶œë°œ)",
        "",
        "*ì‹œê°„ëŒ€ êµ¬ë¶„*",
        "â€¢ ìƒˆë²½ (00-06), ì˜¤ì „1 (06-09)",
        "â€¢ ì˜¤ì „2 (09-12), ì˜¤í›„1 (12-15)",
        "â€¢ ì˜¤í›„2 (15-18), ë°¤1 (18-21)",
        "â€¢ ë°¤2 (21-24)"
    ]
    
    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown"
    )

async def set_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ì„¤ì • ë³€ê²½"""
    user_id = update.effective_user.id
    args = update.message.text.strip().split()
    
    if len(args) < 4:
        await update.message.reply_text(
            "â— ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.\n"
            "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        return
    
    _, direction, set_type, *values = args
    
    if direction not in ["ê°€ëŠ”í¸", "ì˜¤ëŠ”í¸"]:
        await update.message.reply_text("â— 'ê°€ëŠ”í¸' ë˜ëŠ” 'ì˜¤ëŠ”í¸'ë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return
    
    direction = "outbound" if direction == "ê°€ëŠ”í¸" else "inbound"
    config = get_user_config(user_id)
    
    if set_type == "ì‹œê°":
        if len(values) != 1 or not values[0].isdigit():
            await update.message.reply_text("â— ì‹œê°ì€ 0-23 ì‚¬ì´ì˜ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        hour = int(values[0])
        if hour < 0 or hour > 23:
            await update.message.reply_text("â— ì‹œê°ì€ 0-23 ì‚¬ì´ì˜ ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
            
        config['time_type'] = 'exact'
        config[f'{direction}_exact_hour'] = hour
        
    elif set_type == "ì‹œê°„ëŒ€":
        if not values:
            await update.message.reply_text("â— í•˜ë‚˜ ì´ìƒì˜ ì‹œê°„ëŒ€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return
            
        invalid_periods = [p for p in values if p not in TIME_PERIODS]
        if invalid_periods:
            await update.message.reply_text(
                f"â— ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì‹œê°„ëŒ€: {', '.join(invalid_periods)}\n"
                "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
            return
            
        config['time_type'] = 'time_period'
        config[f'{direction}_periods'] = values
        
    else:
        await update.message.reply_text(
            "â— 'ì‹œê°' ë˜ëŠ” 'ì‹œê°„ëŒ€'ë¡œë§Œ ì„¤ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
            "ìì„¸í•œ ì„¤ì • ë°©ë²•ì€ /settings ëª…ë ¹ì–´ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        return
    
    save_user_config(user_id, config)
    await update.message.reply_text(
        f"âœ… {direction=='outbound'and'ê°€ëŠ” í¸'or'ì˜¤ëŠ” í¸'} ì„¤ì •ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤:\n"
        f"{format_time_range(config, direction)}"
    )

# ë¡œê·¸ íŒŒì¼ í¬ê¸° ì œí•œ (10MB)
MAX_LOG_SIZE = 10 * 1024 * 1024

def rotate_logs():
    """ë¡œê·¸ íŒŒì¼ ë¡œí…Œì´ì…˜"""
    if not LOG_FILE.exists() or LOG_FILE.stat().st_size < MAX_LOG_SIZE:
        return
    
    for i in range(4, 0, -1):
        old = LOG_FILE.with_suffix(f'.log.{i}')
        new = LOG_FILE.with_suffix(f'.log.{i+1}')
        if old.exists():
            old.rename(new)
    if LOG_FILE.exists():
        LOG_FILE.rename(LOG_FILE.with_suffix('.log.1'))

rotate_logs()
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-7s | %(name)s | %(filename)s:%(lineno)d | %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

BOT_TOKEN = os.getenv("BOT_TOKEN")
if not BOT_TOKEN:
    logger.error("í™˜ê²½ë³€ìˆ˜ BOT_TOKENì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    raise RuntimeError("BOT_TOKENì´ í•„ìš”í•©ë‹ˆë‹¤.")

SELENIUM_HUB_URL = os.getenv("SELENIUM_HUB_URL", "http://localhost:4444/wd/hub")
USER_AGENT = os.getenv(
    "USER_AGENT",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36"
)
# ì‚¬ìš©ìë‹¹ ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜
MAX_MONITORS = int(os.getenv("MAX_MONITORS", "3"))

raw_admin = os.getenv("ADMIN_IDS", "")
ADMIN_IDS = set(int(p.strip()) for p in raw_admin.split(",") if p.strip().isdigit())

KST = ZoneInfo("Asia/Seoul")
SETTING = 1

# íŒŒì¼ íŒ¨í„´
PATTERN = re.compile(
    r"price_(?P<uid>\d+)_(?P<dep>[A-Z]{3})_(?P<arr>[A-Z]{3})_(?P<dd>\d{8})_(?P<rd>\d{8})\.json"
)

def format_datetime(dt: datetime) -> str:
    return dt.astimezone(KST).strftime('%Y-%m-%d %H:%M:%S')

# í•­ê³µê¶Œ ì¡°íšŒ ë¡œì§
def fetch_prices(depart: str, arrive: str, d_date: str, r_date: str, max_retries=3, user_id=None):
    logger.info(f"fetch_prices í˜¸ì¶œ: {depart}->{arrive} {d_date}~{r_date}")
    url = (
        f"https://flight.naver.com/flights/international/"
        f"{depart}-{arrive}-{d_date}/{arrive}-{depart}-{r_date}?adult=1&fareType=Y"
    )
    
    # ì‚¬ìš©ì ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    if user_id:
        config = get_user_config(user_id)
        outbound_start, outbound_end = get_time_range(config, 'outbound')
        inbound_start, inbound_end = get_time_range(config, 'inbound')
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        outbound_start, outbound_end = get_time_range(DEFAULT_USER_CONFIG, 'outbound')
        inbound_start, inbound_end = get_time_range(DEFAULT_USER_CONFIG, 'inbound')
    
    for attempt in range(max_retries):
        try:
            options = Options()
            options.add_argument("--headless")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument(f"user-agent={USER_AGENT}")
            driver = webdriver.Remote(
                command_executor=SELENIUM_HUB_URL,
                options=options
            )

            overall_price = None
            overall_info = ""
            restricted_price = None
            restricted_info = ""
            try:
                driver.get(url)
                logger.debug("í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ, í•„í„° ëŒ€ê¸° ì¤‘...")
                WebDriverWait(driver, 40).until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, '[class^="inlineFilter_FilterWrapper__"]')
                    )
                )
                time_module.sleep(5)
                items = driver.find_elements(By.XPATH, '//*[@id="international-content"]/div/div[3]/div')
                logger.debug(f"í¬ë¡¤ë§ í•­ëª© ê°œìˆ˜: {len(items)}")
                
                if not items:
                    raise Exception("NO_ITEMS")
                    
                found_any_price = False
                for item in items:
                    text = item.text
                    if "ê²½ìœ " in text:
                        continue
                    m_dep = re.search(rf'(\d{{2}}:\d{{2}}){depart}\s+(\d{{2}}:\d{{2}}){arrive}', text)
                    m_ret = re.search(rf'(\d{{2}}:\d{{2}}){arrive}\s+(\d{{2}}:\d{{2}}){depart}', text)
                    m_price = re.search(r'ì™•ë³µ\s([\d,]+)ì›', text)
                    if not (m_dep and m_ret and m_price):
                        continue
                        
                    found_any_price = True
                    price = int(m_price.group(1).replace(",", ""))
                    if overall_price is None or price < overall_price:
                        overall_price = price
                        overall_info = (
                            f"ê°€ëŠ” í¸: {m_dep.group(1)} â†’ {m_dep.group(2)}\n"
                            f"ì˜¤ëŠ” í¸: {m_ret.group(1)} â†’ {m_ret.group(2)}\n"
                            f"ì™•ë³µ ê°€ê²©: {price:,}ì›"
                        )
                    
                    # ì‹œê°„ ì œí•œ ì ìš©
                    dep_t = datetime.strptime(m_dep.group(1), "%H:%M").time()
                    ret_t = datetime.strptime(m_ret.group(1), "%H:%M").time()
                    
                    # ì‹œê°„ëŒ€ ë˜ëŠ” ì‹œê° ì œí•œ ì²´í¬
                    if config['time_type'] == 'time_period':
                        # ì‹œê°„ëŒ€ ì„¤ì •: ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                        is_valid_outbound = outbound_start <= dep_t <= outbound_end
                        is_valid_inbound = inbound_start <= ret_t <= inbound_end
                    else:
                        # ì‹œê° ì„¤ì •: ì´ì „/ì´í›„ í™•ì¸
                        is_valid_outbound = dep_t <= outbound_end  # ì´ì „
                        is_valid_inbound = ret_t >= inbound_start  # ì´í›„
                    
                    if is_valid_outbound and is_valid_inbound:
                        if restricted_price is None or price < restricted_price:
                            restricted_price = price
                            restricted_info = (
                                f"ê°€ëŠ” í¸: {m_dep.group(1)} â†’ {m_dep.group(2)}\n"
                                f"ì˜¤ëŠ” í¸: {m_ret.group(1)} â†’ {m_ret.group(2)}\n"
                                f"ì™•ë³µ ê°€ê²©: {price:,}ì›"
                            )
                
                if not found_any_price:
                    raise Exception("NO_PRICES")
                    
                return restricted_price, restricted_info, overall_price, overall_info, url
            finally:
                driver.quit()
        except Exception as ex:
            logger.warning(f"fetch_prices ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {ex}")
            if attempt == max_retries - 1:
                if str(ex) in ["NO_ITEMS", "NO_PRICES"]:
                    raise Exception("í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                logger.exception(f"fetch_prices ìµœì¢… ì‹¤íŒ¨: {ex}")
                raise Exception(f"í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {ex}")
            time_module.sleep(5 * (attempt + 1))  # ì ì§„ì ìœ¼ë¡œ ëŒ€ê¸° ì‹œê°„ ì¦ê°€
    
    return None, "ì¡°íšŒ ì‹¤íŒ¨", None, "ì¡°íšŒ ì‹¤íŒ¨", url

# ë„ì›€ë§ í…ìŠ¤íŠ¸
async def help_text() -> str:
    admin_help = ""
    if ADMIN_IDS:
        admin_help = (
            "\n\nğŸ‘‘ *ê´€ë¦¬ì ëª…ë ¹ì–´*\n"
            "â€¢ /all_status - ì „ì²´ ëª¨ë‹ˆí„°ë§ í˜„í™©\n"
            "â€¢ /all_cancel - ì „ì²´ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ"
        )
    
    return (
        "âœˆï¸ *í•­ê³µê¶Œ ìµœì €ê°€ ëª¨ë‹ˆí„°ë§ ë´‡*\n"
        "\n"
        "ğŸ“ *ê¸°ë³¸ ëª…ë ¹ì–´*\n"
        "â€¢ /monitor - ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ ì‹œì‘\n"
        "â€¢ /status - ëª¨ë‹ˆí„°ë§ í˜„í™© í™•ì¸\n"
        "â€¢ /cancel - ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ\n"
        "\n"
        "âš™ï¸ *ì„¤ì • ëª…ë ¹ì–´*\n"
        "â€¢ /settings - ì‹œê°„ ì œí•œ ì„¤ì •\n"
        "â€¢ /airport - ê³µí•­ ì½”ë“œ ëª©ë¡"
        + admin_help
    )

async def help_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /help")
    await update.message.reply_text(await help_text(), parse_mode="Markdown")

async def start(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /start")
    await update.message.reply_text(await help_text(), parse_mode="Markdown")

# í™˜ê²½ë³€ìˆ˜ ê²€ì¦
def validate_env_vars() -> list[str]:
    """í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    Returns:
        list[str]: ì˜¤ë¥˜ ë©”ì‹œì§€ ëª©ë¡
    """
    errors = []
    
    # í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜
    if not os.getenv("BOT_TOKEN"):
        errors.append("BOT_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
    # Selenium Hub URL ê²€ì¦
    selenium_url = os.getenv("SELENIUM_HUB_URL", "http://localhost:4444/wd/hub")
    if not selenium_url.startswith(("http://", "https://")):
        errors.append("SELENIUM_HUB_URLì´ ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤")
        
    # ìˆ«ìí˜• í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    try:
        max_monitors = int(os.getenv("MAX_MONITORS", "3"))
        if max_monitors < 1:
            errors.append("MAX_MONITORSëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    except ValueError:
        errors.append("MAX_MONITORSê°€ ì˜¬ë°”ë¥¸ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤")
        
    try:
        retention_days = int(os.getenv("DATA_RETENTION_DAYS", "30"))
        if retention_days < 1:
            errors.append("DATA_RETENTION_DAYSëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    except ValueError:
        errors.append("DATA_RETENTION_DAYSê°€ ì˜¬ë°”ë¥¸ ìˆ«ìê°€ ì•„ë‹™ë‹ˆë‹¤")
        
    return errors

# ëª…ë ¹ì–´ ì†ë„ ì œí•œ
class RateLimiter:
    def __init__(self, max_calls: int, time_window: float):
        self.max_calls = max_calls
        self.time_window = time_window
        self.calls = defaultdict(list)
        
    def is_allowed(self, user_id: int) -> bool:
        """ì‚¬ìš©ìì˜ ëª…ë ¹ì–´ ì‹¤í–‰ í—ˆìš© ì—¬ë¶€ í™•ì¸"""
        now = time_module.time()
        user_calls = self.calls[user_id]
        
        # ì‹œê°„ ì°½ ë°–ì˜ ê¸°ë¡ ì œê±°
        while user_calls and now - user_calls[0] > self.time_window:
            user_calls.pop(0)
            
        if len(user_calls) >= self.max_calls:
            return False
            
        user_calls.append(now)
        return True

# ì†ë„ ì œí•œ ì„¤ì • (1ë¶„ì— 10íšŒ)
rate_limiter = RateLimiter(max_calls=10, time_window=60)

def rate_limit(func):
    """ëª…ë ¹ì–´ ì†ë„ ì œí•œ ë°ì½”ë ˆì´í„°"""
    async def wrapper(update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        
        if not rate_limiter.is_allowed(user_id):
            await update.message.reply_text(
                "â— ë„ˆë¬´ ë§ì€ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
            return
            
        return await func(update, context)
    return wrapper

@rate_limit
async def monitor_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /monitor")
    msg_lines = [
        "âœˆï¸ *í•­ê³µê¶Œ ëª¨ë‹ˆí„°ë§ ì„¤ì •*",
        "",
        "ì¶œë°œê³µí•­ ë„ì°©ê³µí•­ ê°€ëŠ”ë‚ ì§œ ì˜¤ëŠ”ë‚ ì§œ",
        "ì˜ˆì‹œ: `ICN FUK 20251025 20251027`",
        "",
        "â€¢ ê³µí•­ì½”ë“œ: 3ìë¦¬ ì˜ë¬¸",
        "â€¢ ë‚ ì§œ: YYYYMMDD"
    ]
    await update.message.reply_text("\n".join(msg_lines), parse_mode="Markdown")
    return SETTING

# ìœ íš¨ ë‚ ì§œ ì²´í¬
from datetime import datetime as _dt

def valid_date(d: str) -> tuple[bool, str]:
    """ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
    Returns:
        (bool, str): (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    try:
        date = _dt.strptime(d, "%Y%m%d")
        now = _dt.now()
        
        # ê³¼ê±° ë‚ ì§œ ì²´í¬
        if date.date() < now.date():
            return False, "ê³¼ê±° ë‚ ì§œëŠ” ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
        # 1ë…„ ì´ìƒ ë¯¸ë˜ ì²´í¬
        max_future = now.replace(year=now.year + 1)
        if date > max_future:
            return False, "1ë…„ ì´ìƒ ë¯¸ë˜ì˜ ë‚ ì§œëŠ” ì„ íƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            
        return True, ""
    except ValueError:
        return False, "ì˜¬ë°”ë¥¸ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤ (YYYYMMDD)"

# ê³µí•­ ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬
AIRPORTS = {
    # í•œêµ­
    'KOR': {
        'ICN': ('ì¸ì²œ', 'ì„œìš¸/ì¸ì²œêµ­ì œê³µí•­'),
        'GMP': ('ê¹€í¬', 'ì„œìš¸/ê¹€í¬êµ­ì œê³µí•­'),
        'PUS': ('ë¶€ì‚°', 'ë¶€ì‚°/ê¹€í•´êµ­ì œê³µí•­'),
        'CJU': ('ì œì£¼', 'ì œì£¼êµ­ì œê³µí•­'),
        'TAE': ('ëŒ€êµ¬', 'ëŒ€êµ¬êµ­ì œê³µí•­'),
        'KWJ': ('ê´‘ì£¼', 'ê´‘ì£¼ê³µí•­'),
        'RSU': ('ì—¬ìˆ˜', 'ì—¬ìˆ˜ê³µí•­'),
        'USN': ('ìš¸ì‚°', 'ìš¸ì‚°ê³µí•­'),
        'KPO': ('í¬í•­', 'í¬í•­ê²½ì£¼ê³µí•­'),
        'WJU': ('ì›ì£¼', 'ì›ì£¼ê³µí•­'),
        'YNY': ('ì–‘ì–‘', 'ì–‘ì–‘êµ­ì œê³µí•­'),
        'MWX': ('ë¬´ì•ˆ', 'ë¬´ì•ˆêµ­ì œê³µí•­'),
        'CJJ': ('ì²­ì£¼', 'ì²­ì£¼êµ­ì œê³µí•­'),
    },
    # ì¼ë³¸
    'JPN': {
        'NRT': ('ë‚˜ë¦¬íƒ€', 'ë„ì¿„/ë‚˜ë¦¬íƒ€êµ­ì œê³µí•­'),
        'HND': ('í•˜ë„¤ë‹¤', 'ë„ì¿„/í•˜ë„¤ë‹¤êµ­ì œê³µí•­'),
        'KIX': ('ê°„ì‚¬ì´', 'ì˜¤ì‚¬ì¹´/ê°„ì‚¬ì´êµ­ì œê³µí•­'),
        'ITM': ('ì´íƒ€ë¯¸', 'ì˜¤ì‚¬ì¹´/ì´íƒ€ë¯¸ê³µí•­'),
        'FUK': ('í›„ì¿ ì˜¤ì¹´', 'í›„ì¿ ì˜¤ì¹´ê³µí•­'),
        'CTS': ('ì¹˜í† ì„¸', 'ì‚¿í¬ë¡œ/ì‹ ì¹˜í† ì„¸ê³µí•­'),
        'NGO': ('ë‚˜ê³ ì•¼', 'ë‚˜ê³ ì•¼/ì¤‘ë¶€êµ­ì œê³µí•­'),
        'OKA': ('ë‚˜í•˜', 'ì˜¤í‚¤ë‚˜ì™€/ë‚˜í•˜ê³µí•­'),
        'KOJ': ('ê°€ê³ ì‹œë§ˆ', 'ê°€ê³ ì‹œë§ˆê³µí•­'),
        'HIJ': ('íˆë¡œì‹œë§ˆ', 'íˆë¡œì‹œë§ˆê³µí•­'),
        'SDJ': ('ì„¼ë‹¤ì´', 'ì„¼ë‹¤ì´ê³µí•­'),
        'KMJ': ('êµ¬ë§ˆëª¨í† ', 'êµ¬ë§ˆëª¨í† ê³µí•­'),
        'OKJ': ('ì˜¤ì¹´ì•¼ë§ˆ', 'ì˜¤ì¹´ì•¼ë§ˆê³µí•­'),
        'TAK': ('ë‹¤ì¹´ë§ˆì“°', 'ë‹¤ì¹´ë§ˆì“°ê³µí•­'),
        'MYJ': ('ë§ˆì“°ì•¼ë§ˆ', 'ë§ˆì“°ì•¼ë§ˆê³µí•­'),
        'NGS': ('ë‚˜ê°€ì‚¬í‚¤', 'ë‚˜ê°€ì‚¬í‚¤ê³µí•­'),
    },
    # ì¤‘êµ­
    'CHN': {
        'PEK': ('ë² ì´ì§•/ì„œìš°ë‘', 'ë² ì´ì§•/ì„œìš°ë‘êµ­ì œê³µí•­'),
        'PKX': ('ë² ì´ì§•/ë‹¤ì‹±', 'ë² ì´ì§•/ë‹¤ì‹±êµ­ì œê³µí•­'),
        'PVG': ('ìƒí•˜ì´/í‘¸ë™', 'ìƒí•˜ì´/í‘¸ë™êµ­ì œê³µí•­'),
        'SHA': ('ìƒí•˜ì´/í›™ì°¨ì˜¤', 'ìƒí•˜ì´/í›™ì°¨ì˜¤êµ­ì œê³µí•­'),
        'CAN': ('ê´‘ì €ìš°', 'ê´‘ì €ìš°/ë°”ì´ìœˆêµ­ì œê³µí•­'),
        'SZX': ('ì„ ì „', 'ì„ ì „/ë°”ì˜¤ì•ˆêµ­ì œê³µí•­'),
        'CTU': ('ì²­ë‘', 'ì²­ë‘/ì†½ë¥˜êµ­ì œê³µí•­'),
        'HGH': ('í•­ì €ìš°', 'í•­ì €ìš°/ìƒ¤ì˜¤ì‚°êµ­ì œê³µí•­'),
        'XIY': ('ì‹œì•ˆ', 'ì‹œì•ˆ/ì…´ì–‘êµ­ì œê³µí•­'),
        'DLC': ('ë‹¤ë¡„', 'ë‹¤ë¡„/ì €ìš°ìˆ˜ì´ì¦ˆêµ­ì œê³µí•­'),
        'CSX': ('ì°½ì‚¬', 'ì°½ì‚¬/í™©í™”êµ­ì œê³µí•­'),
        'TAO': ('ì¹­ë‹¤ì˜¤', 'ì¹­ë‹¤ì˜¤/ë¥˜íŒ…êµ­ì œê³µí•­'),
        'NKG': ('ë‚œì§•', 'ë‚œì§•/ë£¨ì»¤ìš°êµ­ì œê³µí•­'),
        'WUH': ('ìš°í•œ', 'ìš°í•œ/í†ˆí—ˆêµ­ì œê³µí•­'),
        'XMN': ('ìƒ¤ë¨¼', 'ìƒ¤ë¨¼/ê°€ì˜¤ì¹˜êµ­ì œê³µí•­'),
        'FOC': ('í‘¸ì €ìš°', 'í‘¸ì €ìš°/ì°½ëŸ¬êµ­ì œê³µí•­'),
    },
    # ë™ë‚¨ì•„ì‹œì•„
    'SEA': {
        'SIN': ('ì‹±ê°€í¬ë¥´', 'ì‹±ê°€í¬ë¥´/ì°½ì´êµ­ì œê³µí•­'),
        'BKK': ('ë°©ì½•', 'ë°©ì½•/ìˆ˜ì™„ë‚˜í’ˆêµ­ì œê³µí•­'),
        'DMK': ('ë°©ì½•/ëˆë¯€ì•™', 'ë°©ì½•/ëˆë¯€ì•™êµ­ì œê³µí•­'),
        'MNL': ('ë§ˆë‹ë¼', 'ë§ˆë‹ë¼/ë‹ˆë…¸ì´ì•„í‚¤ë…¸êµ­ì œê³µí•­'),
        'CGK': ('ìì¹´ë¥´íƒ€', 'ìì¹´ë¥´íƒ€/ìˆ˜ì¹´ë¥´ë…¸í•˜íƒ€êµ­ì œê³µí•­'),
        'KUL': ('ì¿ ì•Œë¼ë£¸í‘¸ë¥´', 'ì¿ ì•Œë¼ë£¸í‘¸ë¥´êµ­ì œê³µí•­'),
        'SGN': ('í˜¸ì¹˜ë¯¼', 'í˜¸ì¹˜ë¯¼/ë–¤ì„ ë…“êµ­ì œê³µí•­'),
        'HAN': ('í•˜ë…¸ì´', 'í•˜ë…¸ì´/ë…¸ì´ë°”ì´êµ­ì œê³µí•­'),
        'RGN': ('ì–‘ê³¤', 'ì–‘ê³¤êµ­ì œê³µí•­'),
        'DPS': ('ë´íŒŒì‚¬ë¥´', 'ë°œë¦¬/ì‘ìš°ë¼ë¼ì´êµ­ì œê³µí•­'),
        'CEB': ('ì„¸ë¶€', 'ì„¸ë¶€/ë§‰íƒ„êµ­ì œê³µí•­'),
        'PNH': ('í”„ë†ˆíœ', 'í”„ë†ˆíœêµ­ì œê³µí•­'),
        'REP': ('ì‹œì— ë¦½', 'ì‹œì— ë¦½êµ­ì œê³µí•­'),
        'BWN': ('ë°˜ë‹¤ë¥´ìŠ¤ë¦¬ë¸Œê°€ì™„', 'ë¸Œë£¨ë‚˜ì´êµ­ì œê³µí•­'),
        'VTE': ('ë¹„ì—”í‹°ì•ˆ', 'ë¹„ì—”í‹°ì•ˆ/ì™“íƒ€ì´êµ­ì œê³µí•­'),
        'DAD': ('ë‹¤ë‚­', 'ë‹¤ë‚­êµ­ì œê³µí•­'),
    },
    # ìœ ëŸ½
    'EUR': {
        'LHR': ('ëŸ°ë˜/íˆë“œë¡œ', 'ëŸ°ë˜/íˆë“œë¡œê³µí•­'),
        'CDG': ('íŒŒë¦¬/ìƒ¤ë¥¼ë“œê³¨', 'íŒŒë¦¬/ìƒ¤ë¥¼ë“œê³¨ê³µí•­'),
        'FRA': ('í”„ë‘í¬í‘¸ë¥´íŠ¸', 'í”„ë‘í¬í‘¸ë¥´íŠ¸êµ­ì œê³µí•­'),
        'AMS': ('ì•”ìŠ¤í…Œë¥´ë‹´', 'ì•”ìŠ¤í…Œë¥´ë‹´/ìŠ¤íˆí´ê³µí•­'),
        'FCO': ('ë¡œë§ˆ', 'ë¡œë§ˆ/í”¼ìš°ë¯¸ì¹˜ë…¸ê³µí•­'),
        'MAD': ('ë§ˆë“œë¦¬ë“œ', 'ë§ˆë“œë¦¬ë“œ/ë°”ë¼í•˜ìŠ¤ê³µí•­'),
        'BCN': ('ë°”ë¥´ì…€ë¡œë‚˜', 'ë°”ë¥´ì…€ë¡œë‚˜/ì—˜í”„ë¼íŠ¸ê³µí•­'),
        'MUC': ('ë®Œí—¨', 'ë®Œí—¨êµ­ì œê³µí•­'),
        'ZRH': ('ì·¨ë¦¬íˆ', 'ì·¨ë¦¬íˆê³µí•­'),
        'VIE': ('ë¹„ì—”ë‚˜', 'ë¹„ì—”ë‚˜êµ­ì œê³µí•­'),
        'CPH': ('ì½”íœí•˜ê²', 'ì½”íœí•˜ê²/ì¹´ìŠ¤íŠ¸ë£¨í”„ê³µí•­'),
        'ARN': ('ìŠ¤í†¡í™€ë¦„', 'ìŠ¤í†¡í™€ë¦„/ì•Œë€ë‹¤ê³µí•­'),
        'OSL': ('ì˜¤ìŠ¬ë¡œ', 'ì˜¤ìŠ¬ë¡œ/ê°€ë¥´ë°ë¥´ëª¨ì—”ê³µí•­'),
        'IST': ('ì´ìŠ¤íƒ„ë¶ˆ', 'ì´ìŠ¤íƒ„ë¶ˆê³µí•­'),
        'DUB': ('ë”ë¸”ë¦°', 'ë”ë¸”ë¦°ê³µí•­'),
        'PRG': ('í”„ë¼í•˜', 'í”„ë¼í•˜/ë°”ì¸¨ë¼í”„í•˜ë²¨ê³µí•­'),
    },
    # ë¯¸ì£¼
    'AMR': {
        'JFK': ('ë‰´ìš•/JFK', 'ë‰´ìš•/ì¡´Fì¼€ë„¤ë””êµ­ì œê³µí•­'),
        'LAX': ('ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤', 'ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤êµ­ì œê³µí•­'),
        'SFO': ('ìƒŒí”„ë€ì‹œìŠ¤ì½”', 'ìƒŒí”„ë€ì‹œìŠ¤ì½”êµ­ì œê³µí•­'),
        'ORD': ('ì‹œì¹´ê³ ', 'ì‹œì¹´ê³ /ì˜¤í—¤ì–´êµ­ì œê³µí•­'),
        'YVR': ('ë°´ì¿ ë²„', 'ë°´ì¿ ë²„êµ­ì œê³µí•­'),
        'YYZ': ('í† ë¡ í† ', 'í† ë¡ í† /í”¼ì–´ìŠ¨êµ­ì œê³µí•­'),
        'HNL': ('í˜¸ë†€ë£°ë£¨', 'í˜¸ë†€ë£°ë£¨/ë‹¤ë‹ˆì—˜Kì´ë…¸ìš°ì—êµ­ì œê³µí•­'),
        'LAS': ('ë¼ìŠ¤ë² ì´ê±°ìŠ¤', 'ë¼ìŠ¤ë² ì´ê±°ìŠ¤/í•´ë¦¬ë¦¬ë“œêµ­ì œê³µí•­'),
        'SEA': ('ì‹œì• í‹€', 'ì‹œì• í‹€/íƒ€ì½”ë§ˆêµ­ì œê³µí•­'),
        'BOS': ('ë³´ìŠ¤í„´', 'ë³´ìŠ¤í„´/ë¡œê±´êµ­ì œê³µí•­'),
        'IAD': ('ì›Œì‹±í„´/ëœë ˆìŠ¤', 'ì›Œì‹±í„´/ëœë ˆìŠ¤êµ­ì œê³µí•­'),
        'YUL': ('ëª¬íŠ¸ë¦¬ì˜¬', 'ëª¬íŠ¸ë¦¬ì˜¬/íŠ¸ë¤¼ë„êµ­ì œê³µí•­'),
        'MEX': ('ë©•ì‹œì½”ì‹œí‹°', 'ë©•ì‹œì½”ì‹œí‹°/ë² ë‹ˆí† í›„ì•„ë ˆìŠ¤êµ­ì œê³µí•­'),
        'GRU': ('ìƒíŒŒìš¸ë£¨', 'ìƒíŒŒìš¸ë£¨/ê³¼ë£°ë¥˜ìŠ¤êµ­ì œê³µí•­'),
        'EZE': ('ë¶€ì—ë…¸ìŠ¤ì•„ì´ë ˆìŠ¤', 'ë¶€ì—ë…¸ìŠ¤ì•„ì´ë ˆìŠ¤/ë¯¸ë‹ˆìŠ¤íŠ¸ë¡œí”¼ìŠ¤íƒ€ë¦¬ë‹ˆêµ­ì œê³µí•­'),
        'SCL': ('ì‚°í‹°ì•„ê³ ', 'ì‚°í‹°ì•„ê³ /ì•„ë¥´íˆ¬ë¡œë©”ë¦¬ë…¸ë² ë‹ˆí…ŒìŠ¤êµ­ì œê³µí•­'),
    },
    # ëŒ€ì–‘ì£¼
    'OCN': {
        'SYD': ('ì‹œë“œë‹ˆ', 'ì‹œë“œë‹ˆ/í‚¹ìŠ¤í¬ë“œìŠ¤ë¯¸ìŠ¤ê³µí•­'),
        'MEL': ('ë©œë²„ë¥¸', 'ë©œë²„ë¥¸ê³µí•­'),
        'BNE': ('ë¸Œë¦¬ì¦ˆë²ˆ', 'ë¸Œë¦¬ì¦ˆë²ˆê³µí•­'),
        'PER': ('í¼ìŠ¤', 'í¼ìŠ¤ê³µí•­'),
        'AKL': ('ì˜¤í´ëœë“œ', 'ì˜¤í´ëœë“œêµ­ì œê³µí•­'),
        'CHC': ('í¬ë¼ì´ìŠ¤íŠ¸ì²˜ì¹˜', 'í¬ë¼ì´ìŠ¤íŠ¸ì²˜ì¹˜êµ­ì œê³µí•­'),
        'WLG': ('ì›°ë§í„´', 'ì›°ë§í„´êµ­ì œê³µí•­'),
        'ADL': ('ì• ë“¤ë ˆì´ë“œ', 'ì• ë“¤ë ˆì´ë“œê³µí•­'),
        'CNS': ('ì¼€ì–¸ì¦ˆ', 'ì¼€ì–¸ì¦ˆê³µí•­'),
        'OOL': ('ê³¨ë“œì½”ìŠ¤íŠ¸', 'ê³¨ë“œì½”ìŠ¤íŠ¸ê³µí•­'),
        'NAN': ('ë‚˜ë””', 'ë‚˜ë””êµ­ì œê³µí•­'),
        'PPT': ('íŒŒí˜ì—í…Œ', 'íŒŒí˜ì—í…Œ/íŒŒì•„ê³µí•­'),
    },
    # ì¤‘ë™
    'MDE': {
        'DXB': ('ë‘ë°”ì´', 'ë‘ë°”ì´êµ­ì œê³µí•­'),
        'DOH': ('ë„í•˜', 'ë„í•˜/í•˜ë§ˆë“œêµ­ì œê³µí•­'),
        'AUH': ('ì•„ë¶€ë‹¤ë¹„', 'ì•„ë¶€ë‹¤ë¹„êµ­ì œê³µí•­'),
        'TLV': ('í…”ì•„ë¹„ë¸Œ', 'í…”ì•„ë¹„ë¸Œ/ë²¤êµ¬ë¦¬ì˜¨êµ­ì œê³µí•­'),
        'BAH': ('ë§ˆë‚˜ë§ˆ', 'ë°”ë ˆì¸êµ­ì œê³µí•­'),
        'MCT': ('ë¬´ìŠ¤ì¹´íŠ¸', 'ë¬´ìŠ¤ì¹´íŠ¸êµ­ì œê³µí•­'),
        'KWI': ('ì¿ ì›¨ì´íŠ¸', 'ì¿ ì›¨ì´íŠ¸êµ­ì œê³µí•­'),
        'JED': ('ì œë‹¤', 'ì œë‹¤/í‚¹ì••ë‘˜ì•„ì§€ì¦ˆêµ­ì œê³µí•­'),
        'RUH': ('ë¦¬ì•¼ë“œ', 'ë¦¬ì•¼ë“œ/í‚¹í• ë¦¬ë“œêµ­ì œê³µí•­'),
    },
}

def get_airport_info(code: str) -> tuple[bool, str, str]:
    """ê³µí•­ ì½”ë“œì˜ ìœ íš¨ì„±ê³¼ ì •ë³´ë¥¼ ë°˜í™˜
    Returns:
        tuple[bool, str, str]: (ìœ íš¨ì„± ì—¬ë¶€, ë„ì‹œëª…, ê³µí•­ëª…)
    """
    code = code.upper()
    for region, airports in AIRPORTS.items():
        if code in airports:
            return True, airports[code][0], airports[code][1]
    return False, "", ""

def format_airport_list() -> str:
    """ì§€ì›í•˜ëŠ” ê³µí•­ ëª©ë¡ì„ í¬ë§¤íŒ…"""
    lines = [
        "âœˆï¸ *ì£¼ìš” ê³µí•­ ì½”ë“œ ëª©ë¡*",
        "_ì•„ë˜ ëª©ë¡ì€ ìì£¼ ì‚¬ìš©ë˜ëŠ” ê³µí•­ì˜ ì˜ˆì‹œì´ë©°,",
        "ì‹¤ì œë¡œëŠ” ë” ë§ì€ ê³µí•­ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤._",
        ""
    ]
    for region, airports in AIRPORTS.items():
        if region == 'KOR':
            region_name = "í•œêµ­"
        elif region == 'JPN':
            region_name = "ì¼ë³¸"
        elif region == 'CHN':
            region_name = "ì¤‘êµ­"
        elif region == 'SEA':
            region_name = "ë™ë‚¨ì•„ì‹œì•„"
        elif region == 'EUR':
            region_name = "ìœ ëŸ½"
        elif region == 'AMR':
            region_name = "ë¯¸ì£¼"
        elif region == 'OCN':
            region_name = "ëŒ€ì–‘ì£¼"
        elif region == 'MDE':
            region_name = "ì¤‘ë™"
        
        lines.append(f"\n*{region_name}*")
        for code, (city, _) in airports.items():
            lines.append(f"â€¢ `{code}`: {city}")
    return "\n".join(lines)

def valid_airport(code: str) -> tuple[bool, str]:
    """ê³µí•­ ì½”ë“œ ìœ íš¨ì„± ê²€ì‚¬ (ê¸°ë³¸ í˜•ì‹ë§Œ ê²€ì‚¬)
    Returns:
        (bool, str): (ìœ íš¨ì„± ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€)
    """
    if not code.isalpha() or len(code) != 3:
        return False, "ê³µí•­ ì½”ë“œëŠ” 3ìë¦¬ ì˜ë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤"
    
    code = code.upper()
    is_valid, city, airport = get_airport_info(code)
    
    # ì•Œë ¤ì§„ ê³µí•­ì´ ì•„ë‹ˆë”ë¼ë„ í˜•ì‹ì´ ë§ìœ¼ë©´ ì¼ë‹¨ í—ˆìš©
    # ì‹¤ì œ ìœ íš¨ì„±ì€ í•­ê³µê¶Œ ì¡°íšŒ ì‹œ í™•ì¸ë¨
    return True, ""

async def monitor_setting(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    text = update.message.text.strip().split()
    logger.debug(f"monitor_setting ì…ë ¥: {text}")
    if len_text := len(text) != 4:
        logger.warning("monitor_setting: í˜•ì‹ ì˜¤ë¥˜")
        await update.message.reply_text(
            "â— í˜•ì‹ ì˜¤ë¥˜\n"
            "âœ… ì˜¬ë°”ë¥¸ í˜•ì‹: `ICN FUK 20251025 20251027`\n"
            "- ê³µí•­ì½”ë“œ: 3ìë¦¬ ì˜ë¬¸\n"
            "- ë‚ ì§œ: YYYYMMDD\n\n"
            "ğŸ’¡ ì£¼ìš” ê³µí•­ ì½”ë“œ ëª©ë¡ì€ /airport ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            parse_mode="Markdown"
        )
        return SETTING

    outbound_dep, outbound_arr, outbound_date, inbound_date = text
    outbound_dep = outbound_dep.upper()
    outbound_arr = outbound_arr.upper()
    
    # ê³µí•­ ì½”ë“œ ê¸°ë³¸ í˜•ì‹ ê²€ì¦
    for code, name in [(outbound_dep, "ì¶œë°œ"), (outbound_arr, "ë„ì°©")]:
        is_valid, msg = valid_airport(code)
        if not is_valid:
            await update.message.reply_text(f"â— {name}ê³µí•­ ì½”ë“œ ì˜¤ë¥˜: {msg}")
            return SETTING
        
    if outbound_dep == outbound_arr:
        await update.message.reply_text("â— ì¶œë°œì§€ì™€ ë„ì°©ì§€ê°€ ê°™ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        return SETTING
    
    # ë‚ ì§œ ê²€ì¦
    is_valid, msg = valid_date(outbound_date)
    if not is_valid:
        await update.message.reply_text(f"â— ê°€ëŠ” í¸ ë‚ ì§œ ì˜¤ë¥˜: {msg}")
        return SETTING
        
    is_valid, msg = valid_date(inbound_date)
    if not is_valid:
        await update.message.reply_text(f"â— ì˜¤ëŠ” í¸ ë‚ ì§œ ì˜¤ë¥˜: {msg}")
        return SETTING
        
    outbound_date_obj = _dt.strptime(outbound_date, "%Y%m%d")
    inbound_date_obj = _dt.strptime(inbound_date, "%Y%m%d")
    if inbound_date_obj <= outbound_date_obj:
        await update.message.reply_text("â— ì˜¤ëŠ” í¸ ë‚ ì§œëŠ” ê°€ëŠ” í¸ ë‚ ì§œë³´ë‹¤ ë’¤ì—¬ì•¼ í•©ë‹ˆë‹¤")
        return SETTING

    user_id = update.effective_user.id
    existing = [p for p in DATA_DIR.iterdir() if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id]
    if len(existing) >= MAX_MONITORS:
        logger.warning(f"ì‚¬ìš©ì {user_id} ìµœëŒ€ ëª¨ë‹ˆí„°ë§ ì´ˆê³¼")
        await update.message.reply_text(f"â— ìµœëŒ€ {MAX_MONITORS}ê°œê¹Œì§€ ëª¨ë‹ˆí„°ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return ConversationHandler.END

    # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    _, dep_city, dep_airport = get_airport_info(outbound_dep)
    _, arr_city, arr_airport = get_airport_info(outbound_arr)
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ê³µí•­ì˜ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
    if not dep_city:
        dep_city = outbound_dep
        dep_airport = f"{outbound_dep}ê³µí•­"
    if not arr_city:
        arr_city = outbound_arr
        arr_airport = f"{outbound_arr}ê³µí•­"

    logger.info(f"ì‚¬ìš©ì {user_id} ì„¤ì •: {outbound_dep}->{outbound_arr} {outbound_date}~{inbound_date}")
    await update.message.reply_text(
        "âœ… *í•­ê³µê¶Œ ëª¨ë‹ˆí„°ë§ ì‹œì‘*\n"
        f"ê°€ëŠ” í¸: {dep_city} ({outbound_dep}) â†’ {arr_city} ({outbound_arr})\n"
        f"ì˜¤ëŠ” í¸: {arr_city} ({outbound_arr}) â†’ {dep_city} ({outbound_dep})\n"
        f"ì¼ì •: {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}\n\n"
        "ğŸ” ì²« ì¡°íšŒ ì¤‘...",
        parse_mode="Markdown"
    )

    try:
        loop = asyncio.get_running_loop()
        restricted, r_info, overall, o_info, link = await loop.run_in_executor(None, fetch_prices, outbound_dep, outbound_arr, outbound_date, inbound_date, user_id)
        
        # ê°€ê²©ì´ ëª¨ë‘ Noneì¸ ê²½ìš°ë„ ì˜¤ë¥˜ë¡œ ì²˜ë¦¬
        if restricted is None and overall is None:
            raise Exception("í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
    except Exception as e:
        logger.warning(f"í•­ê³µê¶Œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        error_msg = str(e)
        if "í•­ê³µê¶Œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in error_msg:
            await update.message.reply_text(
                "â— ì§€ì›í•˜ì§€ ì•ŠëŠ” ê³µí•­ì´ê±°ë‚˜ í•´ë‹¹ ê²½ë¡œì˜ í•­ê³µí¸ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                "ğŸ’¡ ì£¼ìš” ê³µí•­ ì½”ë“œ ëª©ë¡ì€ /airport ëª…ë ¹ìœ¼ë¡œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            await update.message.reply_text(
                "â— í•­ê³µê¶Œ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"
                "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
        return SETTING

    hist_path = DATA_DIR / f"price_{user_id}_{outbound_dep}_{outbound_arr}_{outbound_date}_{inbound_date}.json"
    start_time = format_datetime(datetime.now())
    
    # ì‚¬ìš©ì ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    user_config = get_user_config(user_id)
    
    hist_path.write_text(json.dumps({
        "start_time": start_time,
        "restricted": restricted or 0,
        "overall": overall or 0,
        "last_fetch": format_datetime(datetime.now()),
        "outbound_before": format_time_range(user_config, 'outbound'),
        "outbound_after": format_time_range(user_config, 'outbound'),
        "inbound_before": format_time_range(user_config, 'inbound'),
        "inbound_after": format_time_range(user_config, 'inbound')
    }), encoding="utf-8")

    job = ctx.application.job_queue.run_repeating(
        monitor_job,
        interval=timedelta(minutes=30),
        first=timedelta(seconds=0),
        name=str(hist_path),      
        data={                    
            "chat_id": user_id,
            "settings": (outbound_dep, outbound_arr, outbound_date, inbound_date),
            "hist_path": str(hist_path)
        }
    )

    monitors = ctx.application.bot_data.setdefault("monitors", {})
    monitors.setdefault(user_id, []).append({
        "settings": (outbound_dep, outbound_arr, outbound_date, inbound_date),
        "start_time": datetime.now(KST),
        "hist_path": str(hist_path),
        "job": job
    })

    logger.info(f"ëª¨ë‹ˆí„°ë§ ì‹œì‘ ë“±ë¡: {hist_path}")
    
    # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
    msg_lines = [
        f"âœ… *{dep_city} â†” {arr_city} ëª¨ë‹ˆí„°ë§ ì‹œì‘*",
        f"ğŸ›« ê°€ëŠ” í¸: {dep_airport} â†’ {arr_airport}",
        f"ğŸ›¬ ì˜¤ëŠ” í¸: {arr_airport} â†’ {dep_airport}",
        f"ğŸ“… {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}",
        "",
        "âš™ï¸ *ì ìš©ëœ ì‹œê°„ ì œí•œ*",
        f"â€¢ ê°€ëŠ” í¸: {format_time_range(user_config, 'outbound')}",
        f"â€¢ ì˜¤ëŠ” í¸: {format_time_range(user_config, 'inbound')}",
        "",
        "ğŸ“Š *í˜„ì¬ ìµœì €ê°€*"
    ]
    
    if restricted:
        msg_lines.extend([
            "ğŸ¯ *ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€*",
            r_info,
            ""
        ])
    
    if overall:
        msg_lines.extend([
            "ğŸ“Œ *ì „ì²´ ìµœì €ê°€*",
            o_info
        ])
        
    msg_lines.extend([
        "",
        "â„¹ï¸ 30ë¶„ë§ˆë‹¤ ìë™ìœ¼ë¡œ ê°€ê²©ì„ í™•ì¸í•˜ë©°,",
        "ê°€ê²©ì´ í•˜ë½í•˜ë©´ ì•Œë¦¼ì„ ë³´ë‚´ë“œë¦½ë‹ˆë‹¤.",
        "",
        "ğŸ”— ë„¤ì´ë²„ í•­ê³µê¶Œ:",
        link
    ])
    
    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown",
        disable_web_page_preview=True
    )
    return ConversationHandler.END

async def monitor_job(context: ContextTypes.DEFAULT_TYPE):
    data = context.job.data
    chat_id = data['chat_id']
    outbound_dep, outbound_arr, outbound_date, inbound_date = data['settings']
    hist_path = Path(data['hist_path'])
    logger.info(f"monitor_job ì‹¤í–‰: {outbound_dep}->{outbound_arr}, íˆìŠ¤í† ë¦¬ íŒŒì¼: {hist_path.name}")

    state = json.loads(hist_path.read_text(encoding='utf-8'))
    old_restr = state.get("restricted", 0)
    old_overall = state.get("overall", 0)

    loop = asyncio.get_running_loop()
    restricted, r_info, overall, o_info, link = await loop.run_in_executor(None, fetch_prices, outbound_dep, outbound_arr, outbound_date, inbound_date, chat_id)

    # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    _, dep_city, _ = get_airport_info(outbound_dep)
    _, arr_city, _ = get_airport_info(outbound_arr)

    notify = False
    msg_lines = []
    
    if restricted and restricted < old_restr:
        notify = True
        msg_lines.extend([
            f"ğŸ“‰ *{dep_city} â†” {arr_city} ê°€ê²© í•˜ë½ ì•Œë¦¼*",
            "",
            "ğŸ¯ *ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€*",
            f"ğŸ’° {old_restr:,}ì› â†’ *{restricted:,}ì›* (-{old_restr - restricted:,}ì›)",
            r_info
        ])
        logger.info(f"ì‹œê°„ ì œí•œ ì ìš© ìµœì €ê°€ í•˜ë½: {old_restr} â†’ {restricted}")
        
    if overall and overall < old_overall:
        notify = True
        if not msg_lines:  # ì²« ë²ˆì§¸ ì•Œë¦¼ì¸ ê²½ìš°
            msg_lines.extend([
                f"ğŸ“‰ *{dep_city} â†” {arr_city} ê°€ê²© í•˜ë½ ì•Œë¦¼*",
                ""
            ])
        msg_lines.extend([
            "",
            "ğŸ“Œ *ì „ì²´ ìµœì €ê°€*",
            f"ğŸ’° {old_overall:,}ì› â†’ *{overall:,}ì›* (-{old_overall - overall:,}ì›)",
            o_info
        ])
        logger.info(f"ì „ì²´ ìµœì €ê°€ í•˜ë½: {old_overall} â†’ {overall}")

    if notify:
        msg_lines.extend([
            "",
            f"ğŸ“… {outbound_date[:4]}/{outbound_date[4:6]}/{outbound_date[6:]} â†’ {inbound_date[:4]}/{inbound_date[4:6]}/{inbound_date[6:]}",
            f"[ğŸ”— ë„¤ì´ë²„ í•­ê³µê¶Œ]({link})"
        ])
        await context.bot.send_message(
            chat_id,
            "\n".join(msg_lines),
            parse_mode="Markdown",
            disable_web_page_preview=True
        )
        logger.info("ê°€ê²© í•˜ë½ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")

    new_state = {
        "start_time": state.get("start_time"),
        "restricted": restricted or old_restr,
        "overall": overall or old_overall,
        "last_fetch": format_datetime(datetime.now()),
        "outbound_before": format_time_range(get_user_config(chat_id), 'outbound'),
        "inbound_after": format_time_range(get_user_config(chat_id), 'inbound')
    }
    hist_path.write_text(json.dumps(new_state), encoding='utf-8')
    logger.debug("ìƒíƒœ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

@rate_limit
async def status(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ì‚¬ìš©ì {user_id} ìš”ì²­: /status")
    files = sorted([
        p for p in DATA_DIR.iterdir()
        if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id
    ])
    if not files:
        await update.message.reply_text(
            "í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.\n"
            "ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•˜ë ¤ë©´ /monitor ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”."
        )
        return

    now = datetime.now(KST)
    msg_lines = ["ğŸ“‹ *í˜„ì¬ ëª¨ë‹ˆí„°ë§ ìƒíƒœ*"]

    for idx, hist in enumerate(files, start=1):
        info = PATTERN.fullmatch(hist.name).groupdict()
        data = json.loads(hist.read_text(encoding='utf-8'))
        start_dt = datetime.strptime(
            data['start_time'], '%Y-%m-%d %H:%M:%S'
        ).replace(tzinfo=KST)
        elapsed = (now - start_dt).days
        
        # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        dep, arr = info['dep'], info['arr']
        _, dep_city, _ = get_airport_info(dep)
        _, arr_city, _ = get_airport_info(arr)
        dep_city = dep_city or dep  # ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ê²½ìš° ì½”ë“œ ì‚¬ìš©
        arr_city = arr_city or arr
        
        dd, rd = info['dd'], info['rd']
        
        msg_lines.extend([
            "",
            f"*{idx}. {dep_city}({dep}) â†’ {arr_city}({arr})*",
            f"ğŸ“… {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}",
            "ğŸ’° ìµœì €ê°€ í˜„í™©:",
            f"  â€¢ ì¡°ê±´ë¶€: {data['restricted']:,}ì›" if data['restricted'] else "  â€¢ ì¡°ê±´ë¶€: ì—†ìŒ",
            f"  â€¢ ì „ì²´: {data['overall']:,}ì›" if data['overall'] else "  â€¢ ì „ì²´: ì—†ìŒ",
            f"â±ï¸ ëª¨ë‹ˆí„°ë§ {elapsed}ì¼ì§¸ ì§„í–‰ ì¤‘",
            f"ğŸ”„ ë§ˆì§€ë§‰ ì¡°íšŒ: {data['last_fetch']}"
        ])

    msg_lines.extend([
        "",
        "â„¹ï¸ *ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ ë°©ë²•*:",
        "â€¢ íŠ¹ì • í•­ê³µê¶Œ ì·¨ì†Œ: `/cancel <ë²ˆí˜¸>`",
        "â€¢ ì „ì²´ ì·¨ì†Œ: `/cancel all`",
        "",
        "ğŸ’¡ ìƒˆë¡œìš´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•˜ë ¤ë©´ /monitor ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”."
    ])

    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown"
    )

@rate_limit
async def cancel(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    args = update.message.text.strip().split()
    logger.info(f"ì‚¬ìš©ì {user_id} ìš”ì²­: /cancel {args[1:] if len(args)>1 else ''}")
    if len(args) != 2:
        await update.message.reply_text("â— ì˜¬ë°”ë¥¸ ëª…ë ¹ í˜•ì‹: `/cancel <ë²ˆí˜¸>` ë˜ëŠ” `/cancel all`", parse_mode="Markdown")
        return

    key = args[1].lower()
    files = sorted([
        p for p in DATA_DIR.iterdir()
        if PATTERN.fullmatch(p.name) and int(PATTERN.fullmatch(p.name).group('uid')) == user_id
    ])
    monitors = ctx.application.bot_data.get("monitors", {})
    user_mons = monitors.get(user_id, [])

    if key == 'all':
        if not files:
            await update.message.reply_text("í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        msg_lines = ["âœ… ëª¨ë“  ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤:"]
        for hist in files:
            m = PATTERN.fullmatch(hist.name)
            dep, arr = m.group("dep"), m.group("arr")
            dd, rd = m.group("dd"), m.group("rd")
            # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            _, dep_city, _ = get_airport_info(dep)
            _, arr_city, _ = get_airport_info(arr)
            dep_city = dep_city or dep  # ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ê²½ìš° ì½”ë“œ ì‚¬ìš©
            arr_city = arr_city or arr
            msg_lines.append(
                f"â€¢ {dep_city}({dep}) â†’ {arr_city}({arr})\n"
                f"  {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}"
            )
            hist.unlink()
            for job in ctx.application.job_queue.get_jobs_by_name(str(hist)):
                job.schedule_removal()
        monitors.pop(user_id, None)
        await update.message.reply_text("\n".join(msg_lines))
        logger.info(f"ì‚¬ìš©ì {user_id} ì „ì²´ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ")
        return

    if key.isdigit():
        idx = int(key) - 1
        if idx < 0 or idx >= len(files):
            await update.message.reply_text("â— ìœ íš¨í•˜ì§€ ì•Šì€ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
            return

        target = files[idx]
        m = PATTERN.fullmatch(target.name)
        dep, arr = m.group("dep"), m.group("arr")
        dd, rd = m.group("dd"), m.group("rd")
        # ê³µí•­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        _, dep_city, _ = get_airport_info(dep)
        _, arr_city, _ = get_airport_info(arr)
        dep_city = dep_city or dep  # ë°ì´í„°ë² ì´ìŠ¤ì— ì—†ëŠ” ê²½ìš° ì½”ë“œ ì‚¬ìš©
        arr_city = arr_city or arr
        
        target.unlink()
        for job in ctx.application.job_queue.get_jobs_by_name(str(target)):
            job.schedule_removal()

        if user_id in monitors:
            monitors[user_id] = [m for m in user_mons if m.get('hist_path') != str(target)]
            if not monitors[user_id]:
                monitors.pop(user_id)
                
        msg_lines = [
            "âœ… ë‹¤ìŒ ëª¨ë‹ˆí„°ë§ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤:",
            f"â€¢ {dep_city}({dep}) â†’ {arr_city}({arr})",
            f"  {dd[:4]}/{dd[4:6]}/{dd[6:]} ~ {rd[:4]}/{rd[4:6]}/{rd[6:]}"
        ]
        await update.message.reply_text("\n".join(msg_lines))
        logger.info(f"ì‚¬ìš©ì {user_id} {key}ë²ˆ ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ")
        return

    await update.message.reply_text("â— ì˜¬ë°”ë¥¸ ëª…ë ¹ í˜•ì‹: `/cancel <ë²ˆí˜¸>` ë˜ëŠ” `/cancel all`", parse_mode="Markdown")

async def all_status(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ê´€ë¦¬ì {user_id} ìš”ì²­: /all_status")
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ëª¨ë“  ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì°¾ê¸°
    files = sorted(DATA_DIR.glob("price_*.json"))
    if not files:
        await update.message.reply_text("í˜„ì¬ ë“±ë¡ëœ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ ì§‘ê³„
    user_counts = defaultdict(int)
    for hist_path in files:
        try:
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                continue
            uid = int(m.group("uid"))
            user_counts[uid] += 1
        except Exception as e:
            logger.error(f"ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
    total_users = len(user_counts)
    total_monitors = len(files)
    msg_lines = [
        f"ğŸ“Š *ì „ì²´ ëª¨ë‹ˆí„°ë§ í˜„í™©*",
        f"â€¢ ì´ ì‚¬ìš©ì ìˆ˜: {total_users}ëª…",
        f"â€¢ ì´ ëª¨ë‹ˆí„°ë§ ìˆ˜: {total_monitors}ê±´",
        "",
        "ğŸ“‹ *ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ í˜„í™©*"
    ]

    # ì‚¬ìš©ìë³„ ëª¨ë‹ˆí„°ë§ ê°œìˆ˜ ì •ë ¬ (ê°œìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
    sorted_users = sorted(user_counts.items(), key=lambda x: (-x[1], x[0]))
    for uid, count in sorted_users:
        msg_lines.append(f"â€¢ ì‚¬ìš©ì {uid}: {count}ê±´")

    await update.message.reply_text(
        "\n".join(msg_lines),
        parse_mode="Markdown"
    )

async def all_cancel(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    logger.info(f"ê´€ë¦¬ì {user_id} ìš”ì²­: /all_cancel")
    if user_id not in ADMIN_IDS:
        await update.message.reply_text("âŒ ê´€ë¦¬ì ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    # ëª¨ë“  ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì°¾ê¸°
    files = list(DATA_DIR.glob("price_*.json"))
    if not files:
        await update.message.reply_text("í˜„ì¬ ë“±ë¡ëœ ëª¨ë‹ˆí„°ë§ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    count = 0
    error_count = 0
    processed_users = set()

    for hist_path in files:
        try:
            # íŒŒì¼ëª…ì—ì„œ ì‚¬ìš©ì ID ì¶”ì¶œ
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                continue

            uid = int(m.group("uid"))
            processed_users.add(uid)

            # íŒŒì¼ ì‚­ì œ
            try:
                hist_path.unlink()
                count += 1
            except FileNotFoundError:
                # ì´ë¯¸ ì‚­ì œëœ ê²½ìš°
                pass
            except Exception as e:
                error_count += 1
                logger.error(f"íŒŒì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({hist_path.name}): {e}")

            # ê´€ë ¨ ì‘ì—… ì¤‘ì§€
            for job in ctx.application.job_queue.get_jobs_by_name(str(hist_path)):
                job.schedule_removal()

        except Exception as e:
            error_count += 1
            logger.error(f"ëª¨ë‹ˆí„°ë§ ì·¨ì†Œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë©”ëª¨ë¦¬ ìƒì˜ monitors ë”•ì…”ë„ˆë¦¬ë„ ì •ë¦¬
    monitors = ctx.application.bot_data.get("monitors", {})
    for uid in processed_users:
        monitors.pop(uid, None)

    # ê²°ê³¼ ë©”ì‹œì§€ ìƒì„±
    msg_parts = [f"âœ… ì „ì²´ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ: {count}ê±´ ì²˜ë¦¬ë¨"]
    if error_count > 0:
        msg_parts.append(f"âš ï¸ {error_count}ê±´ì˜ ì˜¤ë¥˜ ë°œìƒ")
    
    await update.message.reply_text("\n".join(msg_parts))
    logger.info(f"ì „ì²´ ëª¨ë‹ˆí„°ë§ ì¢…ë£Œ: {count}ê±´ ì²˜ë¦¬ë¨, {error_count}ê±´ì˜ ì˜¤ë¥˜")

async def on_startup(app):
    now = datetime.now(KST)
    monitors = app.bot_data.setdefault("monitors", {})
    logger.info("ë´‡ ì‹œì‘ ì‹œ on_startup ì‹¤í–‰")
    
    # ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì‘ì—… ì¦‰ì‹œ ì‹¤í–‰
    for hist_path in DATA_DIR.glob("price_*.json"):
        try:
            m = PATTERN.fullmatch(hist_path.name)
            if not m:
                continue
                
            data = json.loads(hist_path.read_text(encoding="utf-8"))
            start_time_str = data.get("start_time")
            try:
                start_time = datetime.strptime(
                    start_time_str,
                    "%Y-%m-%d %H:%M:%S"
                ).replace(tzinfo=KST)
            except Exception:
                start_time = now
                
            # ë§ˆì§€ë§‰ ì¡°íšŒ ì‹œê°„ í™•ì¸
            last_fetch_str = data.get("last_fetch")
            try:
                last_fetch = datetime.strptime(
                    last_fetch_str,
                    "%Y-%m-%d %H:%M:%S"
                ).replace(tzinfo=KST)
            except Exception:
                last_fetch = start_time
                
            # 30ë¶„ ì´ìƒ ì§€ë‚¬ê±°ë‚˜ ë§ˆì§€ë§‰ ì¡°íšŒ ì‹œê°„ì´ ì—†ëŠ” ê²½ìš° ì¦‰ì‹œ ì‹¤í–‰
            interval = timedelta(minutes=30)
            delta = now - last_fetch
            first_delay = timedelta(seconds=0) if delta >= interval else interval - delta
            
            uid = int(m.group("uid"))
            dep, arr, dd, rd = m.group("dep"), m.group("arr"), m.group("dd"), m.group("rd")
            
            # ì¦‰ì‹œ ì‹¤í–‰ì´ í•„ìš”í•œ ê²½ìš° ë³„ë„ì˜ ì¼íšŒì„± ì‘ì—… ì¶”ê°€
            if first_delay == timedelta(seconds=0):
                logger.info(f"ì¦‰ì‹œ ì¡°íšŒ ì˜ˆì•½: {hist_path.name} (ë§ˆì§€ë§‰ ì¡°íšŒ: {last_fetch_str})")
                app.job_queue.run_once(
                    monitor_job,
                    when=0,
                    name=f"{hist_path}_immediate",
                    data={
                        "chat_id": uid,
                        "settings": (dep, arr, dd, rd),
                        "hist_path": str(hist_path)
                    }
                )
            
            # ì •ê¸° ëª¨ë‹ˆí„°ë§ ì‘ì—… ë“±ë¡
            job = app.job_queue.run_repeating(
                monitor_job,
                interval=interval,
                first=first_delay,
                name=str(hist_path),
                data={
                    "chat_id": uid,
                    "settings": (dep, arr, dd, rd),
                    "hist_path": str(hist_path)
                }
            )
            
            monitors.setdefault(uid, []).append({
                "settings": (dep, arr, dd, rd),
                "start_time": start_time,
                "hist_path": str(hist_path),
                "job": job
            })
            logger.info(f"ë³µì›ëœ ëª¨ë‹ˆí„°ë§: {hist_path.name} (ë‹¤ìŒ ì‹¤í–‰: {first_delay.total_seconds():.1f}ì´ˆ í›„)")
        except Exception as ex:
            logger.error(f"ëª¨ë‹ˆí„°ë§ ë³µì› ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({hist_path.name}): {ex}")
            try:
                hist_path.unlink()
                logger.info(f"ì†ìƒëœ ëª¨ë‹ˆí„°ë§ íŒŒì¼ ì‚­ì œ: {hist_path.name}")
            except Exception:
                pass

@contextlib.contextmanager
def file_lock(file_path):
    """íŒŒì¼ ì ê¸ˆì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    lock_path = str(file_path) + '.lock'
    with open(lock_path, 'w') as lock_file:
        try:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_EX)
            yield
        finally:
            fcntl.flock(lock_file.fileno(), fcntl.LOCK_UN)
            if os.path.exists(lock_path):
                os.unlink(lock_path)

def save_json_data(file_path: Path, data: dict):
    """ìŠ¤ë ˆë“œ ì„¸ì´í”„í•œ JSON ë°ì´í„° ì €ì¥"""
    with file_lock(file_path):
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

def load_json_data(file_path: Path) -> dict:
    """ìŠ¤ë ˆë“œ ì„¸ì´í”„í•œ JSON ë°ì´í„° ë¡œë“œ"""
    with file_lock(file_path):
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

async def cleanup_old_data():
    """ì˜¤ë˜ëœ ëª¨ë‹ˆí„°ë§ ë°ì´í„°ì™€ ì„¤ì • íŒŒì¼ ì •ë¦¬"""
    retention_days = int(os.getenv("DATA_RETENTION_DAYS", "30"))
    config_retention_days = 7  # ì„¤ì • íŒŒì¼ ë³´ê´€ ê¸°ê°„
    cutoff_date = datetime.now(KST) - timedelta(days=retention_days)
    config_cutoff_date = datetime.now(KST) - timedelta(days=config_retention_days)
    
    # ì˜¤ë˜ëœ ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì •ë¦¬
    for file_path in DATA_DIR.glob("price_*.json"):
        try:
            data = load_json_data(file_path)
            start_time = datetime.strptime(
                data["start_time"],
                "%Y-%m-%d %H:%M:%S"
            ).replace(tzinfo=KST)
            if start_time < cutoff_date:
                logger.info(f"ì˜¤ë˜ëœ ë°ì´í„° ì‚­ì œ: {file_path.name}")
                file_path.unlink()
        except Exception as ex:
            logger.warning(f"ë°ì´í„° ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {ex}")
    
    # ì˜¤ë˜ëœ ì„¤ì • íŒŒì¼ ì •ë¦¬
    for config_file in USER_CONFIG_DIR.glob("config_*.json"):
        try:
            with file_lock(config_file):
                data = json.loads(config_file.read_text(encoding='utf-8'))
                last_activity = datetime.strptime(
                    data.get('last_activity', data['created_at']),
                    '%Y-%m-%d %H:%M:%S'
                ).replace(tzinfo=KST)
                
                # ë§ˆì§€ë§‰ í™œë™ìœ¼ë¡œë¶€í„° ì¼ì£¼ì¼ì´ ì§€ë‚¬ê³ , í™œì„±í™”ëœ ëª¨ë‹ˆí„°ë§ì´ ì—†ëŠ” ê²½ìš°
                if last_activity < config_cutoff_date:
                    user_id = int(config_file.stem.split('_')[1])
                    active_monitors = [
                        p for p in DATA_DIR.glob(f"price_{user_id}_*.json")
                        if p.exists()
                    ]
                    if not active_monitors:
                        logger.info(f"ë¹„í™œì„± ì‚¬ìš©ì ì„¤ì • ì‚­ì œ: {config_file.name}")
                        config_file.unlink()
        except Exception as ex:
            logger.warning(f"ì„¤ì • íŒŒì¼ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {ex}")

async def airport_cmd(update: Update, ctx: ContextTypes.DEFAULT_TYPE):
    """ê³µí•­ ì½”ë“œ ëª©ë¡ ë³´ê¸°"""
    logger.info(f"ì‚¬ìš©ì {update.effective_user.id} ìš”ì²­: /airport")
    await update.message.reply_text(
        format_airport_list(),
        parse_mode="Markdown"
    )

def main():
    logger.info("ë©”ì¸ í•¨ìˆ˜ ì‹œì‘: ApplicationBuilder ì„¤ì • ì¤‘...")
    
    # í™˜ê²½ë³€ìˆ˜ ê²€ì¦
    errors = validate_env_vars()
    if errors:
        for error in errors:
            logger.error(error)
        return
    
    if not BOT_TOKEN:
        logger.error("í™˜ê²½ë³€ìˆ˜ BOT_TOKENì´ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    application = ApplicationBuilder().token(BOT_TOKEN).build()
    
    # ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    # í•¸ë“¤ëŸ¬ ë“±ë¡
    conv_handler = ConversationHandler(
        entry_points=[CommandHandler("monitor", monitor_cmd)],
        states={
            SETTING: [MessageHandler(filters.TEXT & ~filters.COMMAND, monitor_setting)]
        },
        fallbacks=[],
    )
    
    application.add_handler(conv_handler)
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_cmd))
    application.add_handler(CommandHandler("status", status))
    application.add_handler(CommandHandler("cancel", cancel))
    application.add_handler(CommandHandler("airport", airport_cmd))
    application.add_handler(CommandHandler("settings", settings_cmd))  # ì„¤ì • í™•ì¸
    application.add_handler(CommandHandler("set", set_cmd))  # ì„¤ì • ë³€ê²½
    
    # ê´€ë¦¬ì ëª…ë ¹ì–´
    if ADMIN_IDS:
        application.add_handler(CommandHandler("all_status", all_status))
        application.add_handler(CommandHandler("all_cancel", all_cancel))
    
    # ì‹œì‘ ì‹œ ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ ë³µì›
    application.job_queue.run_once(on_startup, 0)
    
    # ë§¤ì¼ ìì •ì— ì˜¤ë˜ëœ ë°ì´í„° ì •ë¦¬
    application.job_queue.run_daily(
        lambda ctx: asyncio.create_task(cleanup_old_data()),
        time=time(hour=0, minute=0, tzinfo=KST)
    )
    
    logger.info("ë´‡ ì‹¤í–‰ ì‹œì‘")
    application.run_polling()

if __name__ == "__main__":
    main()
